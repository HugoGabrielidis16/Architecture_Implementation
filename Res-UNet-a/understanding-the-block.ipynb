{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hugo/opt/miniconda3/envs/hugginface_env/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 32, 256, 256])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Conv(1,1) : Only used to increase the number of features to the desired initial filter size \n",
    "# Input are either Batch x Channel x Height x Width or Channel x Height x Width\n",
    "conv1_1 = nn.Conv2d(in_channels= 3, out_channels= 32, kernel_size=(1,1), stride=(1,1), padding='same') \n",
    "x = torch.randn((10,3,256,256))\n",
    "y = conv1_1(x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 323, 256, 256])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# UpSample 2\n",
    "# Input has to be Batch x channel x Height x Width\n",
    "upsample2 = nn.Upsample(scale_factor= 2, mode = 'nearest')\n",
    "x = torch.randn((3,323,128,128))\n",
    "y = upsample2(x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3, 128, 128])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## BatchNorm2D\n",
    "# Applies over a 4D input (a mini-batch of 2D inputs with additional channel dimension)\n",
    "norm = nn.BatchNorm2d(num_features=3)\n",
    "x = torch.randn((3,3,128,128))\n",
    "y = norm(x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3, 128, 128])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Max Pooling 2D\n",
    "maxpool = nn.MaxPool2d(kernel_size=2)\n",
    "x = torch.randn((3,3,256,256))\n",
    "y = maxpool(x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 6, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "# Concatenate, seems to be done on the channel axis\n",
    "x = torch.randn((3,3,128,128))\n",
    "y = torch.cat((x,x), dim = 1)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 32, 128, 128])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "class ResUNeta_block(nn.Module):\n",
    "    def __init__(self,input_channels,output_channels,d,kernel_size = 3,stride = 1, padding = 'same' ):\n",
    "        \n",
    "        self.block = []\n",
    "        self.n_block = len(d) # have to reuse it \n",
    "        for dilatation_rate in d: # for every dilation rate we create a new sequential block\n",
    "            self.block.append(\n",
    "                nn.Sequential(\n",
    "                    nn.BatchNorm2d(input_channels),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Conv2d(in_channels=input_channels,\n",
    "                              out_channels=output_channels, \n",
    "                              kernel_size=kernel_size, \n",
    "                              stride=stride, \n",
    "                              padding= padding,\n",
    "                              dilation= dilatation_rate),\n",
    "                    nn.BatchNorm2d(output_channels),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Conv2d(in_channels=output_channels,\n",
    "                              out_channels=output_channels, \n",
    "                              kernel_size=kernel_size, \n",
    "                              stride=stride, \n",
    "                              padding= padding,\n",
    "                              dilation= dilatation_rate)\n",
    "                )\n",
    "            )\n",
    "    def forward(self,x):\n",
    "        result = []\n",
    "        for block in self.block:\n",
    "            rate = block(x)\n",
    "            result.append(rate)\n",
    "        return torch.stack(result, dim=0).sum(dim=0) # this return the sum of all the differents results\n",
    "        \n",
    "block_test = ResUNeta_block(32,32,d = [1,3,15,31])\n",
    "x = torch.randn((64,32,128,128))\n",
    "y = block_test(x)\n",
    "y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 64, 256, 256])\n",
      "torch.Size([10, 32, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "class Combine(nn.Module):\n",
    "    def __init__(self, in_channels,\n",
    "                out_channels,\n",
    "                kernel_size=1,\n",
    "                stride=1,\n",
    "                padding='same',\n",
    "                dilation=1) -> None:\n",
    "        super(Combine,self).__init__()\n",
    "        self.act = nn.ReLU()\n",
    "        self.conv2DN = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=2*in_channels,\n",
    "                out_channels=out_channels,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=stride,\n",
    "                padding=padding,\n",
    "                dilation=dilation),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "\n",
    "       \n",
    "    def forward(self,x1,x2):\n",
    "        x1 = self.act(x1)\n",
    "        concat = torch.concat([x1,x2], dim = 1)\n",
    "        print(concat.shape)\n",
    "        return self.conv2DN(concat)\n",
    "\n",
    "combine_test = Combine(32,32)\n",
    "x = torch.randn((10,32,256,256))\n",
    "y = combine_test(x,x)\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('hugginface_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "84f342ec31c22c66698ab2d3e7e1bc81eb18d4066c64b9d1356118a074cba4d8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
