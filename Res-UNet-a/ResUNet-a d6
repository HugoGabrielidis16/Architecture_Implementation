digraph {
	graph [size="280.34999999999997,280.34999999999997"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	140427605628064 [label="
 ()" fillcolor=darkolivegreen1]
	140427599846704 [label=MeanBackward0]
	140427599846992 -> 140427599846704
	140427599846992 [label=ConvolutionBackward0]
	140427599846848 -> 140427599846992
	140427599846848 [label=NativeBatchNormBackward0]
	140427599847136 -> 140427599846848
	140427599847136 [label=ConvolutionBackward0]
	140427599847328 -> 140427599847136
	140427599847328 [label=CatBackward0]
	140427605717152 -> 140427599847328
	140427605717152 [label=NativeBatchNormBackward0]
	140427605717392 -> 140427605717152
	140427605717392 [label=ConvolutionBackward0]
	140427605717584 -> 140427605717392
	140427605717584 [label=UpsampleNearest2DBackward1]
	140427605717776 -> 140427605717584
	140427605717776 [label=MaxPool2DWithIndicesBackward0]
	140427605717872 -> 140427605717776
	140427605717872 [label=NativeBatchNormBackward0]
	140427605717968 -> 140427605717872
	140427605717968 [label=ConvolutionBackward0]
	140427605718160 -> 140427605717968
	140427605718160 [label=CatBackward0]
	140427605718352 -> 140427605718160
	140427605718352 [label=ReluBackward0]
	140427605718496 -> 140427605718352
	140427605718496 [label=SumBackward1]
	140427605718592 -> 140427605718496
	140427605718592 [label=StackBackward0]
	140427605718688 -> 140427605718592
	140427605718688 [label=NativeBatchNormBackward0]
	140427605718928 -> 140427605718688
	140427605718928 [label=ConvolutionBackward0]
	140427605719120 -> 140427605718928
	140427605719120 [label=CatBackward0]
	140427605719312 -> 140427605719120
	140427605719312 [label=ReluBackward0]
	140427605719456 -> 140427605719312
	140427605719456 [label=UpsampleNearest2DBackward1]
	140427605719552 -> 140427605719456
	140427605719552 [label=SumBackward1]
	140427605719648 -> 140427605719552
	140427605719648 [label=StackBackward0]
	140427605719744 -> 140427605719648
	140427605719744 [label=NativeBatchNormBackward0]
	140427605720032 -> 140427605719744
	140427605720032 [label=ConvolutionBackward0]
	140427605720224 -> 140427605720032
	140427605720224 [label=CatBackward0]
	140427605720416 -> 140427605720224
	140427605720416 [label=ReluBackward0]
	140427605720560 -> 140427605720416
	140427605720560 [label=UpsampleNearest2DBackward1]
	140427605720656 -> 140427605720560
	140427605720656 [label=SumBackward1]
	140427605720752 -> 140427605720656
	140427605720752 [label=StackBackward0]
	140427605720800 -> 140427605720752
	140427605720800 [label=NativeBatchNormBackward0]
	140427605721040 -> 140427605720800
	140427605721040 [label=ConvolutionBackward0]
	140427605725488 -> 140427605721040
	140427605725488 [label=CatBackward0]
	140427605725680 -> 140427605725488
	140427605725680 [label=ReluBackward0]
	140427605725824 -> 140427605725680
	140427605725824 [label=UpsampleNearest2DBackward1]
	140427605725872 -> 140427605725824
	140427605725872 [label=SumBackward1]
	140427605726016 -> 140427605725872
	140427605726016 [label=StackBackward0]
	140427605726160 -> 140427605726016
	140427605726160 [label=NativeBatchNormBackward0]
	140427605726496 -> 140427605726160
	140427605726496 [label=ConvolutionBackward0]
	140427605726688 -> 140427605726496
	140427605726688 [label=CatBackward0]
	140427605726880 -> 140427605726688
	140427605726880 [label=ReluBackward0]
	140427605727024 -> 140427605726880
	140427605727024 [label=UpsampleNearest2DBackward1]
	140427605727072 -> 140427605727024
	140427605727072 [label=SumBackward1]
	140427605727216 -> 140427605727072
	140427605727216 [label=StackBackward0]
	140427605727360 -> 140427605727216
	140427605727360 [label=NativeBatchNormBackward0]
	140427605727600 -> 140427605727360
	140427605727600 [label=ConvolutionBackward0]
	140427605727792 -> 140427605727600
	140427605727792 [label=CatBackward0]
	140427605727984 -> 140427605727792
	140427605727984 [label=ReluBackward0]
	140427605728128 -> 140427605727984
	140427605728128 [label=UpsampleNearest2DBackward1]
	140427605728176 -> 140427605728128
	140427605728176 [label=NativeBatchNormBackward0]
	140427605728320 -> 140427605728176
	140427605728320 [label=ConvolutionBackward0]
	140427605728608 -> 140427605728320
	140427605728608 [label=CatBackward0]
	140427605728800 -> 140427605728608
	140427605728800 [label=NativeBatchNormBackward0]
	140427605729040 -> 140427605728800
	140427605729040 [label=ConvolutionBackward0]
	140427605729232 -> 140427605729040
	140427605729232 [label=UpsampleNearest2DBackward1]
	140427268464848 -> 140427605729232
	140427268464848 [label=MaxPool2DWithIndicesBackward0]
	140427268464896 -> 140427268464848
	140427268464896 [label=SumBackward1]
	140427268465040 -> 140427268464896
	140427268465040 [label=StackBackward0]
	140427268465184 -> 140427268465040
	140427268465184 [label=ConvolutionBackward0]
	140427605727936 -> 140427268465184
	140427605727936 [label=SumBackward1]
	140427268465568 -> 140427605727936
	140427268465568 [label=StackBackward0]
	140427268465616 -> 140427268465568
	140427268465616 [label=ConvolutionBackward0]
	140427605726832 -> 140427268465616
	140427605726832 [label=SumBackward1]
	140427268466000 -> 140427605726832
	140427268466000 [label=StackBackward0]
	140427268466048 -> 140427268466000
	140427268466048 [label=ConvolutionBackward0]
	140427605725632 -> 140427268466048
	140427605725632 [label=SumBackward1]
	140427268466528 -> 140427605725632
	140427268466528 [label=StackBackward0]
	140427268466576 -> 140427268466528
	140427268466576 [label=ConvolutionBackward0]
	140427605720368 -> 140427268466576
	140427605720368 [label=SumBackward1]
	140427268467056 -> 140427605720368
	140427268467056 [label=StackBackward0]
	140427268467104 -> 140427268467056
	140427268467104 [label=ConvolutionBackward0]
	140427605719264 -> 140427268467104
	140427605719264 [label=SumBackward1]
	140427268467632 -> 140427605719264
	140427268467632 [label=StackBackward0]
	140427605718304 -> 140427268467632
	140427605718304 [label=ConvolutionBackward0]
	140427268468016 -> 140427605718304
	140427950173056 [label="encoder.convd_1.weight
 (32, 3, 1, 1)" fillcolor=lightblue]
	140427950173056 -> 140427268468016
	140427268468016 [label=AccumulateGrad]
	140427268467968 -> 140427605718304
	140427950173136 [label="encoder.convd_1.bias
 (32)" fillcolor=lightblue]
	140427950173136 -> 140427268467968
	140427268467968 [label=AccumulateGrad]
	140427268467680 -> 140427268467632
	140427268467680 [label=ConvolutionBackward0]
	140427268468208 -> 140427268467680
	140427268468208 [label=ReluBackward0]
	140427268468400 -> 140427268468208
	140427268468400 [label=NativeBatchNormBackward0]
	140427268468496 -> 140427268468400
	140427268468496 [label=ConvolutionBackward0]
	140427268468688 -> 140427268468496
	140427268468688 [label=ReluBackward0]
	140427268473040 -> 140427268468688
	140427268473040 [label=NativeBatchNormBackward0]
	140427605718304 -> 140427268473040
	140427268473136 -> 140427268473040
	140427950199168 [label="encoder.resblockd_1.block.0.0.weight
 (32)" fillcolor=lightblue]
	140427950199168 -> 140427268473136
	140427268473136 [label=AccumulateGrad]
	140427268473088 -> 140427268473040
	140427950199248 [label="encoder.resblockd_1.block.0.0.bias
 (32)" fillcolor=lightblue]
	140427950199248 -> 140427268473088
	140427268473088 [label=AccumulateGrad]
	140427268468640 -> 140427268468496
	140427950199728 [label="encoder.resblockd_1.block.0.2.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140427950199728 -> 140427268468640
	140427268468640 [label=AccumulateGrad]
	140427268468592 -> 140427268468496
	140427950199808 [label="encoder.resblockd_1.block.0.2.bias
 (32)" fillcolor=lightblue]
	140427950199808 -> 140427268468592
	140427268468592 [label=AccumulateGrad]
	140427268468448 -> 140427268468400
	140427950199888 [label="encoder.resblockd_1.block.0.3.weight
 (32)" fillcolor=lightblue]
	140427950199888 -> 140427268468448
	140427268468448 [label=AccumulateGrad]
	140427268468304 -> 140427268468400
	140427950199968 [label="encoder.resblockd_1.block.0.3.bias
 (32)" fillcolor=lightblue]
	140427950199968 -> 140427268468304
	140427268468304 [label=AccumulateGrad]
	140427268468064 -> 140427268467680
	140427950200288 [label="encoder.resblockd_1.block.0.5.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140427950200288 -> 140427268468064
	140427268468064 [label=AccumulateGrad]
	140427268467920 -> 140427268467680
	140427950200368 [label="encoder.resblockd_1.block.0.5.bias
 (32)" fillcolor=lightblue]
	140427950200368 -> 140427268467920
	140427268467920 [label=AccumulateGrad]
	140427268467536 -> 140427268467632
	140427268467536 [label=ConvolutionBackward0]
	140427268468544 -> 140427268467536
	140427268468544 [label=ReluBackward0]
	140427268473184 -> 140427268468544
	140427268473184 [label=NativeBatchNormBackward0]
	140427268473376 -> 140427268473184
	140427268473376 [label=ConvolutionBackward0]
	140427268473568 -> 140427268473376
	140427268473568 [label=ReluBackward0]
	140427268473760 -> 140427268473568
	140427268473760 [label=NativeBatchNormBackward0]
	140427605718304 -> 140427268473760
	140427268473856 -> 140427268473760
	140427950200448 [label="encoder.resblockd_1.block.1.0.weight
 (32)" fillcolor=lightblue]
	140427950200448 -> 140427268473856
	140427268473856 [label=AccumulateGrad]
	140427268473808 -> 140427268473760
	140427950200528 [label="encoder.resblockd_1.block.1.0.bias
 (32)" fillcolor=lightblue]
	140427950200528 -> 140427268473808
	140427268473808 [label=AccumulateGrad]
	140427268473520 -> 140427268473376
	140427950200848 [label="encoder.resblockd_1.block.1.2.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140427950200848 -> 140427268473520
	140427268473520 [label=AccumulateGrad]
	140427268473472 -> 140427268473376
	140427950200928 [label="encoder.resblockd_1.block.1.2.bias
 (32)" fillcolor=lightblue]
	140427950200928 -> 140427268473472
	140427268473472 [label=AccumulateGrad]
	140427268473328 -> 140427268473184
	140427950201008 [label="encoder.resblockd_1.block.1.3.weight
 (32)" fillcolor=lightblue]
	140427950201008 -> 140427268473328
	140427268473328 [label=AccumulateGrad]
	140427268472992 -> 140427268473184
	140427950201088 [label="encoder.resblockd_1.block.1.3.bias
 (32)" fillcolor=lightblue]
	140427950201088 -> 140427268472992
	140427268472992 [label=AccumulateGrad]
	140427268468352 -> 140427268467536
	140427950201408 [label="encoder.resblockd_1.block.1.5.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140427950201408 -> 140427268468352
	140427268468352 [label=AccumulateGrad]
	140427268468256 -> 140427268467536
	140427950201488 [label="encoder.resblockd_1.block.1.5.bias
 (32)" fillcolor=lightblue]
	140427950201488 -> 140427268468256
	140427268468256 [label=AccumulateGrad]
	140427268467776 -> 140427268467632
	140427268467776 [label=ConvolutionBackward0]
	140427268473424 -> 140427268467776
	140427268473424 [label=ReluBackward0]
	140427268473904 -> 140427268473424
	140427268473904 [label=NativeBatchNormBackward0]
	140427268474000 -> 140427268473904
	140427268474000 [label=ConvolutionBackward0]
	140427268474192 -> 140427268474000
	140427268474192 [label=ReluBackward0]
	140427268474384 -> 140427268474192
	140427268474384 [label=NativeBatchNormBackward0]
	140427605718304 -> 140427268474384
	140427268474480 -> 140427268474384
	140427950201568 [label="encoder.resblockd_1.block.2.0.weight
 (32)" fillcolor=lightblue]
	140427950201568 -> 140427268474480
	140427268474480 [label=AccumulateGrad]
	140427268474432 -> 140427268474384
	140427950201648 [label="encoder.resblockd_1.block.2.0.bias
 (32)" fillcolor=lightblue]
	140427950201648 -> 140427268474432
	140427268474432 [label=AccumulateGrad]
	140427268474144 -> 140427268474000
	140427950201968 [label="encoder.resblockd_1.block.2.2.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140427950201968 -> 140427268474144
	140427268474144 [label=AccumulateGrad]
	140427268474096 -> 140427268474000
	140427950202048 [label="encoder.resblockd_1.block.2.2.bias
 (32)" fillcolor=lightblue]
	140427950202048 -> 140427268474096
	140427268474096 [label=AccumulateGrad]
	140427268473952 -> 140427268473904
	140427950202128 [label="encoder.resblockd_1.block.2.3.weight
 (32)" fillcolor=lightblue]
	140427950202128 -> 140427268473952
	140427268473952 [label=AccumulateGrad]
	140427268473712 -> 140427268473904
	140427950202208 [label="encoder.resblockd_1.block.2.3.bias
 (32)" fillcolor=lightblue]
	140427950202208 -> 140427268473712
	140427268473712 [label=AccumulateGrad]
	140427268472944 -> 140427268467776
	140427950202528 [label="encoder.resblockd_1.block.2.5.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140427950202528 -> 140427268472944
	140427268472944 [label=AccumulateGrad]
	140427268472896 -> 140427268467776
	140427950202608 [label="encoder.resblockd_1.block.2.5.bias
 (32)" fillcolor=lightblue]
	140427950202608 -> 140427268472896
	140427268472896 [label=AccumulateGrad]
	140427268467824 -> 140427268467632
	140427268467824 [label=ConvolutionBackward0]
	140427268474048 -> 140427268467824
	140427268474048 [label=ReluBackward0]
	140427268474528 -> 140427268474048
	140427268474528 [label=NativeBatchNormBackward0]
	140427268474624 -> 140427268474528
	140427268474624 [label=ConvolutionBackward0]
	140427268474816 -> 140427268474624
	140427268474816 [label=ReluBackward0]
	140427268475008 -> 140427268474816
	140427268475008 [label=NativeBatchNormBackward0]
	140427605718304 -> 140427268475008
	140427268475104 -> 140427268475008
	140427950202688 [label="encoder.resblockd_1.block.3.0.weight
 (32)" fillcolor=lightblue]
	140427950202688 -> 140427268475104
	140427268475104 [label=AccumulateGrad]
	140427268475056 -> 140427268475008
	140427950202768 [label="encoder.resblockd_1.block.3.0.bias
 (32)" fillcolor=lightblue]
	140427950202768 -> 140427268475056
	140427268475056 [label=AccumulateGrad]
	140427268474768 -> 140427268474624
	140427950289200 [label="encoder.resblockd_1.block.3.2.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140427950289200 -> 140427268474768
	140427268474768 [label=AccumulateGrad]
	140427268474720 -> 140427268474624
	140427950289280 [label="encoder.resblockd_1.block.3.2.bias
 (32)" fillcolor=lightblue]
	140427950289280 -> 140427268474720
	140427268474720 [label=AccumulateGrad]
	140427268474576 -> 140427268474528
	140427950289360 [label="encoder.resblockd_1.block.3.3.weight
 (32)" fillcolor=lightblue]
	140427950289360 -> 140427268474576
	140427268474576 [label=AccumulateGrad]
	140427268474336 -> 140427268474528
	140427950289440 [label="encoder.resblockd_1.block.3.3.bias
 (32)" fillcolor=lightblue]
	140427950289440 -> 140427268474336
	140427268474336 [label=AccumulateGrad]
	140427268473664 -> 140427268467824
	140427950289760 [label="encoder.resblockd_1.block.3.5.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140427950289760 -> 140427268473664
	140427268473664 [label=AccumulateGrad]
	140427268473616 -> 140427268467824
	140427950289840 [label="encoder.resblockd_1.block.3.5.bias
 (32)" fillcolor=lightblue]
	140427950289840 -> 140427268473616
	140427268473616 [label=AccumulateGrad]
	140427268467488 -> 140427268467104
	140427950173296 [label="encoder.convd_2.weight
 (64, 32, 1, 1)" fillcolor=lightblue]
	140427950173296 -> 140427268467488
	140427268467488 [label=AccumulateGrad]
	140427268467440 -> 140427268467104
	140427950173376 [label="encoder.convd_2.bias
 (64)" fillcolor=lightblue]
	140427950173376 -> 140427268467440
	140427268467440 [label=AccumulateGrad]
	140427268466960 -> 140427268467056
	140427268466960 [label=ConvolutionBackward0]
	140427268467872 -> 140427268466960
	140427268467872 [label=ReluBackward0]
	140427268474864 -> 140427268467872
	140427268474864 [label=NativeBatchNormBackward0]
	140427268474912 -> 140427268474864
	140427268474912 [label=ConvolutionBackward0]
	140427268475296 -> 140427268474912
	140427268475296 [label=ReluBackward0]
	140427268475488 -> 140427268475296
	140427268475488 [label=NativeBatchNormBackward0]
	140427268467104 -> 140427268475488
	140427268475584 -> 140427268475488
	140427950289680 [label="encoder.resblockd_2.block.0.0.weight
 (64)" fillcolor=lightblue]
	140427950289680 -> 140427268475584
	140427268475584 [label=AccumulateGrad]
	140427268475536 -> 140427268475488
	140427950289920 [label="encoder.resblockd_2.block.0.0.bias
 (64)" fillcolor=lightblue]
	140427950289920 -> 140427268475536
	140427268475536 [label=AccumulateGrad]
	140427268475248 -> 140427268474912
	140427950290320 [label="encoder.resblockd_2.block.0.2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140427950290320 -> 140427268475248
	140427268475248 [label=AccumulateGrad]
	140427268475200 -> 140427268474912
	140427950290400 [label="encoder.resblockd_2.block.0.2.bias
 (64)" fillcolor=lightblue]
	140427950290400 -> 140427268475200
	140427268475200 [label=AccumulateGrad]
	140427268474960 -> 140427268474864
	140427950290480 [label="encoder.resblockd_2.block.0.3.weight
 (64)" fillcolor=lightblue]
	140427950290480 -> 140427268474960
	140427268474960 [label=AccumulateGrad]
	140427268474288 -> 140427268474864
	140427950290560 [label="encoder.resblockd_2.block.0.3.bias
 (64)" fillcolor=lightblue]
	140427950290560 -> 140427268474288
	140427268474288 [label=AccumulateGrad]
	140427268467584 -> 140427268466960
	140427950290880 [label="encoder.resblockd_2.block.0.5.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140427950290880 -> 140427268467584
	140427268467584 [label=AccumulateGrad]
	140427268467392 -> 140427268466960
	140427950290960 [label="encoder.resblockd_2.block.0.5.bias
 (64)" fillcolor=lightblue]
	140427950290960 -> 140427268467392
	140427268467392 [label=AccumulateGrad]
	140427268467200 -> 140427268467056
	140427268467200 [label=ConvolutionBackward0]
	140427268475152 -> 140427268467200
	140427268475152 [label=ReluBackward0]
	140427268475632 -> 140427268475152
	140427268475632 [label=NativeBatchNormBackward0]
	140427268475728 -> 140427268475632
	140427268475728 [label=ConvolutionBackward0]
	140427268475920 -> 140427268475728
	140427268475920 [label=ReluBackward0]
	140427268476112 -> 140427268475920
	140427268476112 [label=NativeBatchNormBackward0]
	140427268467104 -> 140427268476112
	140427268476208 -> 140427268476112
	140427950291040 [label="encoder.resblockd_2.block.1.0.weight
 (64)" fillcolor=lightblue]
	140427950291040 -> 140427268476208
	140427268476208 [label=AccumulateGrad]
	140427268476160 -> 140427268476112
	140427950291120 [label="encoder.resblockd_2.block.1.0.bias
 (64)" fillcolor=lightblue]
	140427950291120 -> 140427268476160
	140427268476160 [label=AccumulateGrad]
	140427268475872 -> 140427268475728
	140427950291440 [label="encoder.resblockd_2.block.1.2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140427950291440 -> 140427268475872
	140427268475872 [label=AccumulateGrad]
	140427268475824 -> 140427268475728
	140427950291520 [label="encoder.resblockd_2.block.1.2.bias
 (64)" fillcolor=lightblue]
	140427950291520 -> 140427268475824
	140427268475824 [label=AccumulateGrad]
	140427268475680 -> 140427268475632
	140427950291600 [label="encoder.resblockd_2.block.1.3.weight
 (64)" fillcolor=lightblue]
	140427950291600 -> 140427268475680
	140427268475680 [label=AccumulateGrad]
	140427268475440 -> 140427268475632
	140427950291680 [label="encoder.resblockd_2.block.1.3.bias
 (64)" fillcolor=lightblue]
	140427950291680 -> 140427268475440
	140427268475440 [label=AccumulateGrad]
	140427268474672 -> 140427268467200
	140427950292000 [label="encoder.resblockd_2.block.1.5.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140427950292000 -> 140427268474672
	140427268474672 [label=AccumulateGrad]
	140427268474240 -> 140427268467200
	140427950292080 [label="encoder.resblockd_2.block.1.5.bias
 (64)" fillcolor=lightblue]
	140427950292080 -> 140427268474240
	140427268474240 [label=AccumulateGrad]
	140427268467248 -> 140427268467056
	140427268467248 [label=ConvolutionBackward0]
	140427268475776 -> 140427268467248
	140427268475776 [label=ReluBackward0]
	140427268476256 -> 140427268475776
	140427268476256 [label=NativeBatchNormBackward0]
	140427268476352 -> 140427268476256
	140427268476352 [label=ConvolutionBackward0]
	140427268476544 -> 140427268476352
	140427268476544 [label=ReluBackward0]
	140427268476736 -> 140427268476544
	140427268476736 [label=NativeBatchNormBackward0]
	140427268467104 -> 140427268476736
	140427268476832 -> 140427268476736
	140427950292160 [label="encoder.resblockd_2.block.2.0.weight
 (64)" fillcolor=lightblue]
	140427950292160 -> 140427268476832
	140427268476832 [label=AccumulateGrad]
	140427268476784 -> 140427268476736
	140427950292240 [label="encoder.resblockd_2.block.2.0.bias
 (64)" fillcolor=lightblue]
	140427950292240 -> 140427268476784
	140427268476784 [label=AccumulateGrad]
	140427268476496 -> 140427268476352
	140427950292560 [label="encoder.resblockd_2.block.2.2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140427950292560 -> 140427268476496
	140427268476496 [label=AccumulateGrad]
	140427268476448 -> 140427268476352
	140427950292640 [label="encoder.resblockd_2.block.2.2.bias
 (64)" fillcolor=lightblue]
	140427950292640 -> 140427268476448
	140427268476448 [label=AccumulateGrad]
	140427268476304 -> 140427268476256
	140427950292720 [label="encoder.resblockd_2.block.2.3.weight
 (64)" fillcolor=lightblue]
	140427950292720 -> 140427268476304
	140427268476304 [label=AccumulateGrad]
	140427268476064 -> 140427268476256
	140427950292800 [label="encoder.resblockd_2.block.2.3.bias
 (64)" fillcolor=lightblue]
	140427950292800 -> 140427268476064
	140427268476064 [label=AccumulateGrad]
	140427268475392 -> 140427268467248
	140427950387424 [label="encoder.resblockd_2.block.2.5.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140427950387424 -> 140427268475392
	140427268475392 [label=AccumulateGrad]
	140427268475344 -> 140427268467248
	140427950387504 [label="encoder.resblockd_2.block.2.5.bias
 (64)" fillcolor=lightblue]
	140427950387504 -> 140427268475344
	140427268475344 [label=AccumulateGrad]
	140427268467296 -> 140427268467056
	140427268467296 [label=ConvolutionBackward0]
	140427268476400 -> 140427268467296
	140427268476400 [label=ReluBackward0]
	140427268476880 -> 140427268476400
	140427268476880 [label=NativeBatchNormBackward0]
	140427268513952 -> 140427268476880
	140427268513952 [label=ConvolutionBackward0]
	140427268514144 -> 140427268513952
	140427268514144 [label=ReluBackward0]
	140427268514336 -> 140427268514144
	140427268514336 [label=NativeBatchNormBackward0]
	140427268467104 -> 140427268514336
	140427268514432 -> 140427268514336
	140427950387584 [label="encoder.resblockd_2.block.3.0.weight
 (64)" fillcolor=lightblue]
	140427950387584 -> 140427268514432
	140427268514432 [label=AccumulateGrad]
	140427268514384 -> 140427268514336
	140427950387664 [label="encoder.resblockd_2.block.3.0.bias
 (64)" fillcolor=lightblue]
	140427950387664 -> 140427268514384
	140427268514384 [label=AccumulateGrad]
	140427268514096 -> 140427268513952
	140427950387984 [label="encoder.resblockd_2.block.3.2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140427950387984 -> 140427268514096
	140427268514096 [label=AccumulateGrad]
	140427268514048 -> 140427268513952
	140427950388064 [label="encoder.resblockd_2.block.3.2.bias
 (64)" fillcolor=lightblue]
	140427950388064 -> 140427268514048
	140427268514048 [label=AccumulateGrad]
	140427268513856 -> 140427268476880
	140427950388144 [label="encoder.resblockd_2.block.3.3.weight
 (64)" fillcolor=lightblue]
	140427950388144 -> 140427268513856
	140427268513856 [label=AccumulateGrad]
	140427268513904 -> 140427268476880
	140427950388224 [label="encoder.resblockd_2.block.3.3.bias
 (64)" fillcolor=lightblue]
	140427950388224 -> 140427268513904
	140427268513904 [label=AccumulateGrad]
	140427268476016 -> 140427268467296
	140427950388544 [label="encoder.resblockd_2.block.3.5.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140427950388544 -> 140427268476016
	140427268476016 [label=AccumulateGrad]
	140427268475968 -> 140427268467296
	140427950388624 [label="encoder.resblockd_2.block.3.5.bias
 (64)" fillcolor=lightblue]
	140427950388624 -> 140427268475968
	140427268475968 [label=AccumulateGrad]
	140427268466912 -> 140427268466576
	140427950173536 [label="encoder.convd_3.weight
 (128, 64, 1, 1)" fillcolor=lightblue]
	140427950173536 -> 140427268466912
	140427268466912 [label=AccumulateGrad]
	140427268466864 -> 140427268466576
	140427950173616 [label="encoder.convd_3.bias
 (128)" fillcolor=lightblue]
	140427950173616 -> 140427268466864
	140427268466864 [label=AccumulateGrad]
	140427268466432 -> 140427268466528
	140427268466432 [label=ConvolutionBackward0]
	140427268467344 -> 140427268466432
	140427268467344 [label=ReluBackward0]
	140427268476640 -> 140427268467344
	140427268476640 [label=NativeBatchNormBackward0]
	140427268514240 -> 140427268476640
	140427268514240 [label=ConvolutionBackward0]
	140427268514624 -> 140427268514240
	140427268514624 [label=ReluBackward0]
	140427268514816 -> 140427268514624
	140427268514816 [label=NativeBatchNormBackward0]
	140427268466576 -> 140427268514816
	140427268514912 -> 140427268514816
	140427950388464 [label="encoder.resblockd_3.block.0.0.weight
 (128)" fillcolor=lightblue]
	140427950388464 -> 140427268514912
	140427268514912 [label=AccumulateGrad]
	140427268514864 -> 140427268514816
	140427950388704 [label="encoder.resblockd_3.block.0.0.bias
 (128)" fillcolor=lightblue]
	140427950388704 -> 140427268514864
	140427268514864 [label=AccumulateGrad]
	140427268514576 -> 140427268514240
	140427950389104 [label="encoder.resblockd_3.block.0.2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	140427950389104 -> 140427268514576
	140427268514576 [label=AccumulateGrad]
	140427268514528 -> 140427268514240
	140427950389184 [label="encoder.resblockd_3.block.0.2.bias
 (128)" fillcolor=lightblue]
	140427950389184 -> 140427268514528
	140427268514528 [label=AccumulateGrad]
	140427268514288 -> 140427268476640
	140427950389264 [label="encoder.resblockd_3.block.0.3.weight
 (128)" fillcolor=lightblue]
	140427950389264 -> 140427268514288
	140427268514288 [label=AccumulateGrad]
	140427268514000 -> 140427268476640
	140427950389344 [label="encoder.resblockd_3.block.0.3.bias
 (128)" fillcolor=lightblue]
	140427950389344 -> 140427268514000
	140427268514000 [label=AccumulateGrad]
	140427268467008 -> 140427268466432
	140427950389664 [label="encoder.resblockd_3.block.0.5.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	140427950389664 -> 140427268467008
	140427268467008 [label=AccumulateGrad]
	140427268466816 -> 140427268466432
	140427950389744 [label="encoder.resblockd_3.block.0.5.bias
 (128)" fillcolor=lightblue]
	140427950389744 -> 140427268466816
	140427268466816 [label=AccumulateGrad]
	140427268466672 -> 140427268466528
	140427268466672 [label=ConvolutionBackward0]
	140427268476592 -> 140427268466672
	140427268476592 [label=ReluBackward0]
	140427268514960 -> 140427268476592
	140427268514960 [label=NativeBatchNormBackward0]
	140427268515056 -> 140427268514960
	140427268515056 [label=ConvolutionBackward0]
	140427268515248 -> 140427268515056
	140427268515248 [label=ReluBackward0]
	140427268515440 -> 140427268515248
	140427268515440 [label=NativeBatchNormBackward0]
	140427268466576 -> 140427268515440
	140427268515536 -> 140427268515440
	140427950389824 [label="encoder.resblockd_3.block.1.0.weight
 (128)" fillcolor=lightblue]
	140427950389824 -> 140427268515536
	140427268515536 [label=AccumulateGrad]
	140427268515488 -> 140427268515440
	140427950389904 [label="encoder.resblockd_3.block.1.0.bias
 (128)" fillcolor=lightblue]
	140427950389904 -> 140427268515488
	140427268515488 [label=AccumulateGrad]
	140427268515200 -> 140427268515056
	140427950390224 [label="encoder.resblockd_3.block.1.2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	140427950390224 -> 140427268515200
	140427268515200 [label=AccumulateGrad]
	140427268515152 -> 140427268515056
	140427950390304 [label="encoder.resblockd_3.block.1.2.bias
 (128)" fillcolor=lightblue]
	140427950390304 -> 140427268515152
	140427268515152 [label=AccumulateGrad]
	140427268515008 -> 140427268514960
	140427950390384 [label="encoder.resblockd_3.block.1.3.weight
 (128)" fillcolor=lightblue]
	140427950390384 -> 140427268515008
	140427268515008 [label=AccumulateGrad]
	140427268514768 -> 140427268514960
	140427950390464 [label="encoder.resblockd_3.block.1.3.bias
 (128)" fillcolor=lightblue]
	140427950390464 -> 140427268514768
	140427268514768 [label=AccumulateGrad]
	140427268514480 -> 140427268466672
	140427950390784 [label="encoder.resblockd_3.block.1.5.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	140427950390784 -> 140427268514480
	140427268514480 [label=AccumulateGrad]
	140427268514192 -> 140427268466672
	140427950390864 [label="encoder.resblockd_3.block.1.5.bias
 (128)" fillcolor=lightblue]
	140427950390864 -> 140427268514192
	140427268514192 [label=AccumulateGrad]
	140427268466720 -> 140427268466528
	140427268466720 [label=ConvolutionBackward0]
	140427268515104 -> 140427268466720
	140427268515104 [label=ReluBackward0]
	140427268515584 -> 140427268515104
	140427268515584 [label=NativeBatchNormBackward0]
	140427268515680 -> 140427268515584
	140427268515680 [label=ConvolutionBackward0]
	140427268515872 -> 140427268515680
	140427268515872 [label=ReluBackward0]
	140427268516064 -> 140427268515872
	140427268516064 [label=NativeBatchNormBackward0]
	140427268466576 -> 140427268516064
	140427268516160 -> 140427268516064
	140427950390944 [label="encoder.resblockd_3.block.2.0.weight
 (128)" fillcolor=lightblue]
	140427950390944 -> 140427268516160
	140427268516160 [label=AccumulateGrad]
	140427268516112 -> 140427268516064
	140427950391024 [label="encoder.resblockd_3.block.2.0.bias
 (128)" fillcolor=lightblue]
	140427950391024 -> 140427268516112
	140427268516112 [label=AccumulateGrad]
	140427268515824 -> 140427268515680
	140427954430096 [label="encoder.resblockd_3.block.2.2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	140427954430096 -> 140427268515824
	140427268515824 [label=AccumulateGrad]
	140427268515776 -> 140427268515680
	140427954430176 [label="encoder.resblockd_3.block.2.2.bias
 (128)" fillcolor=lightblue]
	140427954430176 -> 140427268515776
	140427268515776 [label=AccumulateGrad]
	140427268515632 -> 140427268515584
	140427954430256 [label="encoder.resblockd_3.block.2.3.weight
 (128)" fillcolor=lightblue]
	140427954430256 -> 140427268515632
	140427268515632 [label=AccumulateGrad]
	140427268515392 -> 140427268515584
	140427954430336 [label="encoder.resblockd_3.block.2.3.bias
 (128)" fillcolor=lightblue]
	140427954430336 -> 140427268515392
	140427268515392 [label=AccumulateGrad]
	140427268514720 -> 140427268466720
	140427954430656 [label="encoder.resblockd_3.block.2.5.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	140427954430656 -> 140427268514720
	140427268514720 [label=AccumulateGrad]
	140427268514672 -> 140427268466720
	140427954430736 [label="encoder.resblockd_3.block.2.5.bias
 (128)" fillcolor=lightblue]
	140427954430736 -> 140427268514672
	140427268514672 [label=AccumulateGrad]
	140427268466384 -> 140427268466048
	140427950173776 [label="encoder.convd_4.weight
 (256, 128, 1, 1)" fillcolor=lightblue]
	140427950173776 -> 140427268466384
	140427268466384 [label=AccumulateGrad]
	140427268466336 -> 140427268466048
	140427950173856 [label="encoder.convd_4.bias
 (256)" fillcolor=lightblue]
	140427950173856 -> 140427268466336
	140427268466336 [label=AccumulateGrad]
	140427268465904 -> 140427268466000
	140427268465904 [label=ConvolutionBackward0]
	140427268466768 -> 140427268465904
	140427268466768 [label=ReluBackward0]
	140427268515920 -> 140427268466768
	140427268515920 [label=NativeBatchNormBackward0]
	140427268515968 -> 140427268515920
	140427268515968 [label=ConvolutionBackward0]
	140427268516352 -> 140427268515968
	140427268516352 [label=ReluBackward0]
	140427268516544 -> 140427268516352
	140427268516544 [label=NativeBatchNormBackward0]
	140427268466048 -> 140427268516544
	140427268516640 -> 140427268516544
	140427954430576 [label="encoder.resblockd_4.block.0.0.weight
 (256)" fillcolor=lightblue]
	140427954430576 -> 140427268516640
	140427268516640 [label=AccumulateGrad]
	140427268516592 -> 140427268516544
	140427954430816 [label="encoder.resblockd_4.block.0.0.bias
 (256)" fillcolor=lightblue]
	140427954430816 -> 140427268516592
	140427268516592 [label=AccumulateGrad]
	140427268516304 -> 140427268515968
	140427954431216 [label="encoder.resblockd_4.block.0.2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140427954431216 -> 140427268516304
	140427268516304 [label=AccumulateGrad]
	140427268516256 -> 140427268515968
	140427954431296 [label="encoder.resblockd_4.block.0.2.bias
 (256)" fillcolor=lightblue]
	140427954431296 -> 140427268516256
	140427268516256 [label=AccumulateGrad]
	140427268516016 -> 140427268515920
	140427954431376 [label="encoder.resblockd_4.block.0.3.weight
 (256)" fillcolor=lightblue]
	140427954431376 -> 140427268516016
	140427268516016 [label=AccumulateGrad]
	140427268515344 -> 140427268515920
	140427954431456 [label="encoder.resblockd_4.block.0.3.bias
 (256)" fillcolor=lightblue]
	140427954431456 -> 140427268515344
	140427268515344 [label=AccumulateGrad]
	140427268466480 -> 140427268465904
	140427954431776 [label="encoder.resblockd_4.block.0.5.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140427954431776 -> 140427268466480
	140427268466480 [label=AccumulateGrad]
	140427268466288 -> 140427268465904
	140427954431856 [label="encoder.resblockd_4.block.0.5.bias
 (256)" fillcolor=lightblue]
	140427954431856 -> 140427268466288
	140427268466288 [label=AccumulateGrad]
	140427268466144 -> 140427268466000
	140427268466144 [label=ConvolutionBackward0]
	140427268516208 -> 140427268466144
	140427268516208 [label=ReluBackward0]
	140427268516688 -> 140427268516208
	140427268516688 [label=NativeBatchNormBackward0]
	140427268516784 -> 140427268516688
	140427268516784 [label=ConvolutionBackward0]
	140427268516976 -> 140427268516784
	140427268516976 [label=ReluBackward0]
	140427268517168 -> 140427268516976
	140427268517168 [label=NativeBatchNormBackward0]
	140427268466048 -> 140427268517168
	140427268517264 -> 140427268517168
	140427954431936 [label="encoder.resblockd_4.block.1.0.weight
 (256)" fillcolor=lightblue]
	140427954431936 -> 140427268517264
	140427268517264 [label=AccumulateGrad]
	140427268517216 -> 140427268517168
	140427954432016 [label="encoder.resblockd_4.block.1.0.bias
 (256)" fillcolor=lightblue]
	140427954432016 -> 140427268517216
	140427268517216 [label=AccumulateGrad]
	140427268516928 -> 140427268516784
	140427954432336 [label="encoder.resblockd_4.block.1.2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140427954432336 -> 140427268516928
	140427268516928 [label=AccumulateGrad]
	140427268516880 -> 140427268516784
	140427954432416 [label="encoder.resblockd_4.block.1.2.bias
 (256)" fillcolor=lightblue]
	140427954432416 -> 140427268516880
	140427268516880 [label=AccumulateGrad]
	140427268516736 -> 140427268516688
	140427954432496 [label="encoder.resblockd_4.block.1.3.weight
 (256)" fillcolor=lightblue]
	140427954432496 -> 140427268516736
	140427268516736 [label=AccumulateGrad]
	140427268516496 -> 140427268516688
	140427954432576 [label="encoder.resblockd_4.block.1.3.bias
 (256)" fillcolor=lightblue]
	140427954432576 -> 140427268516496
	140427268516496 [label=AccumulateGrad]
	140427268515728 -> 140427268466144
	140427954432896 [label="encoder.resblockd_4.block.1.5.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140427954432896 -> 140427268515728
	140427268515728 [label=AccumulateGrad]
	140427268515296 -> 140427268466144
	140427954432976 [label="encoder.resblockd_4.block.1.5.bias
 (256)" fillcolor=lightblue]
	140427954432976 -> 140427268515296
	140427268515296 [label=AccumulateGrad]
	140427268466192 -> 140427268466000
	140427268466192 [label=ConvolutionBackward0]
	140427268516832 -> 140427268466192
	140427268516832 [label=ReluBackward0]
	140427268517312 -> 140427268516832
	140427268517312 [label=NativeBatchNormBackward0]
	140427268517408 -> 140427268517312
	140427268517408 [label=ConvolutionBackward0]
	140427268517600 -> 140427268517408
	140427268517600 [label=ReluBackward0]
	140427268517792 -> 140427268517600
	140427268517792 [label=NativeBatchNormBackward0]
	140427268466048 -> 140427268517792
	140427268517840 -> 140427268517792
	140427954433056 [label="encoder.resblockd_4.block.2.0.weight
 (256)" fillcolor=lightblue]
	140427954433056 -> 140427268517840
	140427268517840 [label=AccumulateGrad]
	140427268517696 -> 140427268517792
	140427954433136 [label="encoder.resblockd_4.block.2.0.bias
 (256)" fillcolor=lightblue]
	140427954433136 -> 140427268517696
	140427268517696 [label=AccumulateGrad]
	140427268517552 -> 140427268517408
	140427954433456 [label="encoder.resblockd_4.block.2.2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140427954433456 -> 140427268517552
	140427268517552 [label=AccumulateGrad]
	140427268517504 -> 140427268517408
	140427954433536 [label="encoder.resblockd_4.block.2.2.bias
 (256)" fillcolor=lightblue]
	140427954433536 -> 140427268517504
	140427268517504 [label=AccumulateGrad]
	140427268517360 -> 140427268517312
	140427954433616 [label="encoder.resblockd_4.block.2.3.weight
 (256)" fillcolor=lightblue]
	140427954433616 -> 140427268517360
	140427268517360 [label=AccumulateGrad]
	140427268517120 -> 140427268517312
	140427954433696 [label="encoder.resblockd_4.block.2.3.bias
 (256)" fillcolor=lightblue]
	140427954433696 -> 140427268517120
	140427268517120 [label=AccumulateGrad]
	140427268516448 -> 140427268466192
	140427954536512 [label="encoder.resblockd_4.block.2.5.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140427954536512 -> 140427268516448
	140427268516448 [label=AccumulateGrad]
	140427268516400 -> 140427268466192
	140427954536592 [label="encoder.resblockd_4.block.2.5.bias
 (256)" fillcolor=lightblue]
	140427954536592 -> 140427268516400
	140427268516400 [label=AccumulateGrad]
	140427268465856 -> 140427268465616
	140427950174016 [label="encoder.convd_5.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	140427950174016 -> 140427268465856
	140427268465856 [label=AccumulateGrad]
	140427268465808 -> 140427268465616
	140427950174096 [label="encoder.convd_5.bias
 (512)" fillcolor=lightblue]
	140427950174096 -> 140427268465808
	140427268465808 [label=AccumulateGrad]
	140427268465472 -> 140427268465568
	140427268465472 [label=ConvolutionBackward0]
	140427268466240 -> 140427268465472
	140427268466240 [label=ReluBackward0]
	140427268517648 -> 140427268466240
	140427268517648 [label=NativeBatchNormBackward0]
	140427268517744 -> 140427268517648
	140427268517744 [label=ConvolutionBackward0]
	140427268546816 -> 140427268517744
	140427268546816 [label=ReluBackward0]
	140427268547008 -> 140427268546816
	140427268547008 [label=NativeBatchNormBackward0]
	140427268465616 -> 140427268547008
	140427268547104 -> 140427268547008
	140427954433936 [label="encoder.resblockd_5.block.0.0.weight
 (512)" fillcolor=lightblue]
	140427954433936 -> 140427268547104
	140427268547104 [label=AccumulateGrad]
	140427268547056 -> 140427268547008
	140427954536672 [label="encoder.resblockd_5.block.0.0.bias
 (512)" fillcolor=lightblue]
	140427954536672 -> 140427268547056
	140427268547056 [label=AccumulateGrad]
	140427268546768 -> 140427268517744
	140427954537072 [label="encoder.resblockd_5.block.0.2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	140427954537072 -> 140427268546768
	140427268546768 [label=AccumulateGrad]
	140427268546720 -> 140427268517744
	140427954537152 [label="encoder.resblockd_5.block.0.2.bias
 (512)" fillcolor=lightblue]
	140427954537152 -> 140427268546720
	140427268546720 [label=AccumulateGrad]
	140427268517072 -> 140427268517648
	140427954537232 [label="encoder.resblockd_5.block.0.3.weight
 (512)" fillcolor=lightblue]
	140427954537232 -> 140427268517072
	140427268517072 [label=AccumulateGrad]
	140427268546624 -> 140427268517648
	140427954537312 [label="encoder.resblockd_5.block.0.3.bias
 (512)" fillcolor=lightblue]
	140427954537312 -> 140427268546624
	140427268546624 [label=AccumulateGrad]
	140427268465952 -> 140427268465472
	140427954537632 [label="encoder.resblockd_5.block.0.5.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	140427954537632 -> 140427268465952
	140427268465952 [label=AccumulateGrad]
	140427268465760 -> 140427268465472
	140427954537712 [label="encoder.resblockd_5.block.0.5.bias
 (512)" fillcolor=lightblue]
	140427954537712 -> 140427268465760
	140427268465760 [label=AccumulateGrad]
	140427268465424 -> 140427268465184
	140427950198928 [label="encoder.convd_6.weight
 (1024, 512, 1, 1)" fillcolor=lightblue]
	140427950198928 -> 140427268465424
	140427268465424 [label=AccumulateGrad]
	140427268465376 -> 140427268465184
	140427950199008 [label="encoder.convd_6.bias
 (1024)" fillcolor=lightblue]
	140427950199008 -> 140427268465376
	140427268465376 [label=AccumulateGrad]
	140427268465136 -> 140427268465040
	140427268465136 [label=ConvolutionBackward0]
	140427268465712 -> 140427268465136
	140427268465712 [label=ReluBackward0]
	140427268517456 -> 140427268465712
	140427268517456 [label=NativeBatchNormBackward0]
	140427268546912 -> 140427268517456
	140427268546912 [label=ConvolutionBackward0]
	140427268547296 -> 140427268546912
	140427268547296 [label=ReluBackward0]
	140427268547488 -> 140427268547296
	140427268547488 [label=NativeBatchNormBackward0]
	140427268465184 -> 140427268547488
	140427268547584 -> 140427268547488
	140427954537792 [label="encoder.resblockd_6.block.0.0.weight
 (1024)" fillcolor=lightblue]
	140427954537792 -> 140427268547584
	140427268547584 [label=AccumulateGrad]
	140427268547536 -> 140427268547488
	140427954537872 [label="encoder.resblockd_6.block.0.0.bias
 (1024)" fillcolor=lightblue]
	140427954537872 -> 140427268547536
	140427268547536 [label=AccumulateGrad]
	140427268547248 -> 140427268546912
	140427954538192 [label="encoder.resblockd_6.block.0.2.weight
 (1024, 1024, 3, 3)" fillcolor=lightblue]
	140427954538192 -> 140427268547248
	140427268547248 [label=AccumulateGrad]
	140427268547200 -> 140427268546912
	140427954538272 [label="encoder.resblockd_6.block.0.2.bias
 (1024)" fillcolor=lightblue]
	140427954538272 -> 140427268547200
	140427268547200 [label=AccumulateGrad]
	140427268546960 -> 140427268517456
	140427954538352 [label="encoder.resblockd_6.block.0.3.weight
 (1024)" fillcolor=lightblue]
	140427954538352 -> 140427268546960
	140427268546960 [label=AccumulateGrad]
	140427268546672 -> 140427268517456
	140427954538432 [label="encoder.resblockd_6.block.0.3.bias
 (1024)" fillcolor=lightblue]
	140427954538432 -> 140427268546672
	140427268546672 [label=AccumulateGrad]
	140427268465520 -> 140427268465136
	140427954538752 [label="encoder.resblockd_6.block.0.5.weight
 (1024, 1024, 3, 3)" fillcolor=lightblue]
	140427954538752 -> 140427268465520
	140427268465520 [label=AccumulateGrad]
	140427268465328 -> 140427268465136
	140427954538832 [label="encoder.resblockd_6.block.0.5.bias
 (1024)" fillcolor=lightblue]
	140427954538832 -> 140427268465328
	140427268465328 [label=AccumulateGrad]
	140427605729184 -> 140427605729040
	140427954538912 [label="bottleneck.parrallel_list.0.2.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	140427954538912 -> 140427605729184
	140427605729184 [label=AccumulateGrad]
	140427605729136 -> 140427605729040
	140427954538992 [label="bottleneck.parrallel_list.0.2.bias
 (256)" fillcolor=lightblue]
	140427954538992 -> 140427605729136
	140427605729136 [label=AccumulateGrad]
	140427605728992 -> 140427605728800
	140427954539072 [label="bottleneck.parrallel_list.0.3.weight
 (256)" fillcolor=lightblue]
	140427954539072 -> 140427605728992
	140427605728992 [label=AccumulateGrad]
	140427605728944 -> 140427605728800
	140427954539152 [label="bottleneck.parrallel_list.0.3.bias
 (256)" fillcolor=lightblue]
	140427954539152 -> 140427605728944
	140427605728944 [label=AccumulateGrad]
	140427605728752 -> 140427605728608
	140427605728752 [label=NativeBatchNormBackward0]
	140427605729088 -> 140427605728752
	140427605729088 [label=ConvolutionBackward0]
	140427268517024 -> 140427605729088
	140427268517024 [label=UpsampleNearest2DBackward1]
	140427268547440 -> 140427268517024
	140427268547440 [label=MaxPool2DWithIndicesBackward0]
	140427268464896 -> 140427268547440
	140427268465280 -> 140427605729088
	140427954539472 [label="bottleneck.parrallel_list.1.2.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	140427954539472 -> 140427268465280
	140427268465280 [label=AccumulateGrad]
	140427268464992 -> 140427605729088
	140427954539552 [label="bottleneck.parrallel_list.1.2.bias
 (256)" fillcolor=lightblue]
	140427954539552 -> 140427268464992
	140427268464992 [label=AccumulateGrad]
	140427268464800 -> 140427605728752
	140427954539632 [label="bottleneck.parrallel_list.1.3.weight
 (256)" fillcolor=lightblue]
	140427954539632 -> 140427268464800
	140427268464800 [label=AccumulateGrad]
	140427268464704 -> 140427605728752
	140427954539712 [label="bottleneck.parrallel_list.1.3.bias
 (256)" fillcolor=lightblue]
	140427954539712 -> 140427268464704
	140427268464704 [label=AccumulateGrad]
	140427605728704 -> 140427605728608
	140427605728704 [label=NativeBatchNormBackward0]
	140427268464752 -> 140427605728704
	140427268464752 [label=ConvolutionBackward0]
	140427268547680 -> 140427268464752
	140427268547680 [label=UpsampleNearest2DBackward1]
	140427268547872 -> 140427268547680
	140427268547872 [label=MaxPool2DWithIndicesBackward0]
	140427268464896 -> 140427268547872
	140427268547152 -> 140427268464752
	140427954540032 [label="bottleneck.parrallel_list.2.2.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	140427954540032 -> 140427268547152
	140427268547152 [label=AccumulateGrad]
	140427268547392 -> 140427268464752
	140427954540112 [label="bottleneck.parrallel_list.2.2.bias
 (256)" fillcolor=lightblue]
	140427954540112 -> 140427268547392
	140427268547392 [label=AccumulateGrad]
	140427268547344 -> 140427605728704
	140427954540192 [label="bottleneck.parrallel_list.2.3.weight
 (256)" fillcolor=lightblue]
	140427954540192 -> 140427268547344
	140427268547344 [label=AccumulateGrad]
	140427268546864 -> 140427605728704
	140427954540272 [label="bottleneck.parrallel_list.2.3.bias
 (256)" fillcolor=lightblue]
	140427954540272 -> 140427268546864
	140427268546864 [label=AccumulateGrad]
	140427605728848 -> 140427605728608
	140427605728848 [label=NativeBatchNormBackward0]
	140427268547824 -> 140427605728848
	140427268547824 [label=ConvolutionBackward0]
	140427268548016 -> 140427268547824
	140427268548016 [label=UpsampleNearest2DBackward1]
	140427268548208 -> 140427268548016
	140427268548208 [label=MaxPool2DWithIndicesBackward0]
	140427268464896 -> 140427268548208
	140427268547776 -> 140427268547824
	140427556577424 [label="bottleneck.parrallel_list.3.2.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	140427556577424 -> 140427268547776
	140427268547776 [label=AccumulateGrad]
	140427268547920 -> 140427268547824
	140427556577504 [label="bottleneck.parrallel_list.3.2.bias
 (256)" fillcolor=lightblue]
	140427556577504 -> 140427268547920
	140427268547920 [label=AccumulateGrad]
	140427268547728 -> 140427605728848
	140427556577584 [label="bottleneck.parrallel_list.3.3.weight
 (256)" fillcolor=lightblue]
	140427556577584 -> 140427268547728
	140427268547728 [label=AccumulateGrad]
	140427268547632 -> 140427605728848
	140427556577664 [label="bottleneck.parrallel_list.3.3.bias
 (256)" fillcolor=lightblue]
	140427556577664 -> 140427268547632
	140427268547632 [label=AccumulateGrad]
	140427605728560 -> 140427605728320
	140427556577904 [label="bottleneck.conv.0.weight
 (1024, 1024, 1, 1)" fillcolor=lightblue]
	140427556577904 -> 140427605728560
	140427605728560 [label=AccumulateGrad]
	140427605728512 -> 140427605728320
	140427556577984 [label="bottleneck.conv.0.bias
 (1024)" fillcolor=lightblue]
	140427556577984 -> 140427605728512
	140427605728512 [label=AccumulateGrad]
	140427605728272 -> 140427605728176
	140427556578064 [label="bottleneck.conv.1.weight
 (1024)" fillcolor=lightblue]
	140427556578064 -> 140427605728272
	140427605728272 [label=AccumulateGrad]
	140427605728416 -> 140427605728176
	140427556578144 [label="bottleneck.conv.1.bias
 (1024)" fillcolor=lightblue]
	140427556578144 -> 140427605728416
	140427605728416 [label=AccumulateGrad]
	140427605727936 -> 140427605727792
	140427605727744 -> 140427605727600
	140427599852304 [label="decoder.combine_1.conv2DN.0.weight
 (512, 1536, 1, 1)" fillcolor=lightblue]
	140427599852304 -> 140427605727744
	140427605727744 [label=AccumulateGrad]
	140427605727696 -> 140427605727600
	140427599852544 [label="decoder.combine_1.conv2DN.0.bias
 (512)" fillcolor=lightblue]
	140427599852544 -> 140427605727696
	140427605727696 [label=AccumulateGrad]
	140427605727552 -> 140427605727360
	140427599852624 [label="decoder.combine_1.conv2DN.1.weight
 (512)" fillcolor=lightblue]
	140427599852624 -> 140427605727552
	140427605727552 [label=AccumulateGrad]
	140427605727504 -> 140427605727360
	140427599852704 [label="decoder.combine_1.conv2DN.1.bias
 (512)" fillcolor=lightblue]
	140427599852704 -> 140427605727504
	140427605727504 [label=AccumulateGrad]
	140427605727312 -> 140427605727216
	140427605727312 [label=ConvolutionBackward0]
	140427605727888 -> 140427605727312
	140427605727888 [label=ReluBackward0]
	140427605728656 -> 140427605727888
	140427605728656 [label=NativeBatchNormBackward0]
	140427605728032 -> 140427605728656
	140427605728032 [label=ConvolutionBackward0]
	140427268548112 -> 140427605728032
	140427268548112 [label=ReluBackward0]
	140427268548496 -> 140427268548112
	140427268548496 [label=NativeBatchNormBackward0]
	140427605727360 -> 140427268548496
	140427268548592 -> 140427268548496
	140427556578544 [label="decoder.resblockup_1.block.0.0.weight
 (512)" fillcolor=lightblue]
	140427556578544 -> 140427268548592
	140427268548592 [label=AccumulateGrad]
	140427268548544 -> 140427268548496
	140427556578624 [label="decoder.resblockup_1.block.0.0.bias
 (512)" fillcolor=lightblue]
	140427556578624 -> 140427268548544
	140427268548544 [label=AccumulateGrad]
	140427268548256 -> 140427605728032
	140427556578944 [label="decoder.resblockup_1.block.0.2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	140427556578944 -> 140427268548256
	140427268548256 [label=AccumulateGrad]
	140427268548304 -> 140427605728032
	140427556579024 [label="decoder.resblockup_1.block.0.2.bias
 (512)" fillcolor=lightblue]
	140427556579024 -> 140427268548304
	140427268548304 [label=AccumulateGrad]
	140427268548064 -> 140427605728656
	140427556579104 [label="decoder.resblockup_1.block.0.3.weight
 (512)" fillcolor=lightblue]
	140427556579104 -> 140427268548064
	140427268548064 [label=AccumulateGrad]
	140427268547968 -> 140427605728656
	140427556579184 [label="decoder.resblockup_1.block.0.3.bias
 (512)" fillcolor=lightblue]
	140427556579184 -> 140427268547968
	140427268547968 [label=AccumulateGrad]
	140427605727840 -> 140427605727312
	140427556579504 [label="decoder.resblockup_1.block.0.5.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	140427556579504 -> 140427605727840
	140427605727840 [label=AccumulateGrad]
	140427605727648 -> 140427605727312
	140427556579584 [label="decoder.resblockup_1.block.0.5.bias
 (512)" fillcolor=lightblue]
	140427556579584 -> 140427605727648
	140427605727648 [label=AccumulateGrad]
	140427605726832 -> 140427605726688
	140427605726640 -> 140427605726496
	140427599853104 [label="decoder.combine_2.conv2DN.0.weight
 (256, 768, 1, 1)" fillcolor=lightblue]
	140427599853104 -> 140427605726640
	140427605726640 [label=AccumulateGrad]
	140427605726592 -> 140427605726496
	140427599853184 [label="decoder.combine_2.conv2DN.0.bias
 (256)" fillcolor=lightblue]
	140427599853184 -> 140427605726592
	140427605726592 [label=AccumulateGrad]
	140427605726448 -> 140427605726160
	140427599853264 [label="decoder.combine_2.conv2DN.1.weight
 (256)" fillcolor=lightblue]
	140427599853264 -> 140427605726448
	140427605726448 [label=AccumulateGrad]
	140427605726400 -> 140427605726160
	140427599853344 [label="decoder.combine_2.conv2DN.1.bias
 (256)" fillcolor=lightblue]
	140427599853344 -> 140427605726400
	140427605726400 [label=AccumulateGrad]
	140427605726112 -> 140427605726016
	140427605726112 [label=ConvolutionBackward0]
	140427605726784 -> 140427605726112
	140427605726784 [label=ReluBackward0]
	140427605727456 -> 140427605726784
	140427605727456 [label=NativeBatchNormBackward0]
	140427605728464 -> 140427605727456
	140427605728464 [label=ConvolutionBackward0]
	140427268548400 -> 140427605728464
	140427268548400 [label=ReluBackward0]
	140427268548784 -> 140427268548400
	140427268548784 [label=NativeBatchNormBackward0]
	140427605726160 -> 140427268548784
	140427268548880 -> 140427268548784
	140427556579664 [label="decoder.resblockup_2.block.0.0.weight
 (256)" fillcolor=lightblue]
	140427556579664 -> 140427268548880
	140427268548880 [label=AccumulateGrad]
	140427268548832 -> 140427268548784
	140427556579744 [label="decoder.resblockup_2.block.0.0.bias
 (256)" fillcolor=lightblue]
	140427556579744 -> 140427268548832
	140427268548832 [label=AccumulateGrad]
	140427268548448 -> 140427605728464
	140427556580064 [label="decoder.resblockup_2.block.0.2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140427556580064 -> 140427268548448
	140427268548448 [label=AccumulateGrad]
	140427268548352 -> 140427605728464
	140427556580144 [label="decoder.resblockup_2.block.0.2.bias
 (256)" fillcolor=lightblue]
	140427556580144 -> 140427268548352
	140427268548352 [label=AccumulateGrad]
	140427605728080 -> 140427605727456
	140427556580224 [label="decoder.resblockup_2.block.0.3.weight
 (256)" fillcolor=lightblue]
	140427556580224 -> 140427605728080
	140427605728080 [label=AccumulateGrad]
	140427605726928 -> 140427605727456
	140427556580304 [label="decoder.resblockup_2.block.0.3.bias
 (256)" fillcolor=lightblue]
	140427556580304 -> 140427605726928
	140427605726928 [label=AccumulateGrad]
	140427605726736 -> 140427605726112
	140427556580624 [label="decoder.resblockup_2.block.0.5.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140427556580624 -> 140427605726736
	140427605726736 [label=AccumulateGrad]
	140427605726544 -> 140427605726112
	140427556580704 [label="decoder.resblockup_2.block.0.5.bias
 (256)" fillcolor=lightblue]
	140427556580704 -> 140427605726544
	140427605726544 [label=AccumulateGrad]
	140427605726256 -> 140427605726016
	140427605726256 [label=ConvolutionBackward0]
	140427605727168 -> 140427605726256
	140427605727168 [label=ReluBackward0]
	140427268548928 -> 140427605727168
	140427268548928 [label=NativeBatchNormBackward0]
	140427268549024 -> 140427268548928
	140427268549024 [label=ConvolutionBackward0]
	140427268549216 -> 140427268549024
	140427268549216 [label=ReluBackward0]
	140427268549408 -> 140427268549216
	140427268549408 [label=NativeBatchNormBackward0]
	140427605726160 -> 140427268549408
	140427268549504 -> 140427268549408
	140427556580784 [label="decoder.resblockup_2.block.1.0.weight
 (256)" fillcolor=lightblue]
	140427556580784 -> 140427268549504
	140427268549504 [label=AccumulateGrad]
	140427268549456 -> 140427268549408
	140427556580864 [label="decoder.resblockup_2.block.1.0.bias
 (256)" fillcolor=lightblue]
	140427556580864 -> 140427268549456
	140427268549456 [label=AccumulateGrad]
	140427268549168 -> 140427268549024
	140427556581184 [label="decoder.resblockup_2.block.1.2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140427556581184 -> 140427268549168
	140427268549168 [label=AccumulateGrad]
	140427268549120 -> 140427268549024
	140427556581264 [label="decoder.resblockup_2.block.1.2.bias
 (256)" fillcolor=lightblue]
	140427556581264 -> 140427268549120
	140427268549120 [label=AccumulateGrad]
	140427268548976 -> 140427268548928
	140427556687936 [label="decoder.resblockup_2.block.1.3.weight
 (256)" fillcolor=lightblue]
	140427556687936 -> 140427268548976
	140427268548976 [label=AccumulateGrad]
	140427268548736 -> 140427268548928
	140427556688016 [label="decoder.resblockup_2.block.1.3.bias
 (256)" fillcolor=lightblue]
	140427556688016 -> 140427268548736
	140427268548736 [label=AccumulateGrad]
	140427605726976 -> 140427605726256
	140427556688336 [label="decoder.resblockup_2.block.1.5.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140427556688336 -> 140427605726976
	140427605726976 [label=AccumulateGrad]
	140427268548160 -> 140427605726256
	140427556688416 [label="decoder.resblockup_2.block.1.5.bias
 (256)" fillcolor=lightblue]
	140427556688416 -> 140427268548160
	140427268548160 [label=AccumulateGrad]
	140427605726304 -> 140427605726016
	140427605726304 [label=ConvolutionBackward0]
	140427268549072 -> 140427605726304
	140427268549072 [label=ReluBackward0]
	140427268549552 -> 140427268549072
	140427268549552 [label=NativeBatchNormBackward0]
	140427268549648 -> 140427268549552
	140427268549648 [label=ConvolutionBackward0]
	140427268549840 -> 140427268549648
	140427268549840 [label=ReluBackward0]
	140427268550032 -> 140427268549840
	140427268550032 [label=NativeBatchNormBackward0]
	140427605726160 -> 140427268550032
	140427268550128 -> 140427268550032
	140427556688496 [label="decoder.resblockup_2.block.2.0.weight
 (256)" fillcolor=lightblue]
	140427556688496 -> 140427268550128
	140427268550128 [label=AccumulateGrad]
	140427268550080 -> 140427268550032
	140427556688576 [label="decoder.resblockup_2.block.2.0.bias
 (256)" fillcolor=lightblue]
	140427556688576 -> 140427268550080
	140427268550080 [label=AccumulateGrad]
	140427268549792 -> 140427268549648
	140427556688896 [label="decoder.resblockup_2.block.2.2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140427556688896 -> 140427268549792
	140427268549792 [label=AccumulateGrad]
	140427268549744 -> 140427268549648
	140427556688976 [label="decoder.resblockup_2.block.2.2.bias
 (256)" fillcolor=lightblue]
	140427556688976 -> 140427268549744
	140427268549744 [label=AccumulateGrad]
	140427268549600 -> 140427268549552
	140427556689056 [label="decoder.resblockup_2.block.2.3.weight
 (256)" fillcolor=lightblue]
	140427556689056 -> 140427268549600
	140427268549600 [label=AccumulateGrad]
	140427268549360 -> 140427268549552
	140427556689136 [label="decoder.resblockup_2.block.2.3.bias
 (256)" fillcolor=lightblue]
	140427556689136 -> 140427268549360
	140427268549360 [label=AccumulateGrad]
	140427268548688 -> 140427605726304
	140427556689456 [label="decoder.resblockup_2.block.2.5.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140427556689456 -> 140427268548688
	140427268548688 [label=AccumulateGrad]
	140427268548640 -> 140427605726304
	140427556689536 [label="decoder.resblockup_2.block.2.5.bias
 (256)" fillcolor=lightblue]
	140427556689536 -> 140427268548640
	140427268548640 [label=AccumulateGrad]
	140427605725632 -> 140427605725488
	140427605725440 -> 140427605721040
	140427599853664 [label="decoder.combine_3.conv2DN.0.weight
 (128, 384, 1, 1)" fillcolor=lightblue]
	140427599853664 -> 140427605725440
	140427605725440 [label=AccumulateGrad]
	140427605725392 -> 140427605721040
	140427599853744 [label="decoder.combine_3.conv2DN.0.bias
 (128)" fillcolor=lightblue]
	140427599853744 -> 140427605725392
	140427605725392 [label=AccumulateGrad]
	140427605725296 -> 140427605720800
	140427599853824 [label="decoder.combine_3.conv2DN.1.weight
 (128)" fillcolor=lightblue]
	140427599853824 -> 140427605725296
	140427605725296 [label=AccumulateGrad]
	140427605725248 -> 140427605720800
	140427599853904 [label="decoder.combine_3.conv2DN.1.bias
 (128)" fillcolor=lightblue]
	140427599853904 -> 140427605725248
	140427605725248 [label=AccumulateGrad]
	140427605720464 -> 140427605720752
	140427605720464 [label=ConvolutionBackward0]
	140427605725584 -> 140427605720464
	140427605725584 [label=ReluBackward0]
	140427605726352 -> 140427605725584
	140427605726352 [label=NativeBatchNormBackward0]
	140427605725728 -> 140427605726352
	140427605725728 [label=ConvolutionBackward0]
	140427268549936 -> 140427605725728
	140427268549936 [label=ReluBackward0]
	140427268550320 -> 140427268549936
	140427268550320 [label=NativeBatchNormBackward0]
	140427605720800 -> 140427268550320
	140427268550416 -> 140427268550320
	140427556689376 [label="decoder.resblockup_3.block.0.0.weight
 (128)" fillcolor=lightblue]
	140427556689376 -> 140427268550416
	140427268550416 [label=AccumulateGrad]
	140427268550368 -> 140427268550320
	140427556689616 [label="decoder.resblockup_3.block.0.0.bias
 (128)" fillcolor=lightblue]
	140427556689616 -> 140427268550368
	140427268550368 [label=AccumulateGrad]
	140427268549984 -> 140427605725728
	140427556690016 [label="decoder.resblockup_3.block.0.2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	140427556690016 -> 140427268549984
	140427268549984 [label=AccumulateGrad]
	140427268549888 -> 140427605725728
	140427556690096 [label="decoder.resblockup_3.block.0.2.bias
 (128)" fillcolor=lightblue]
	140427556690096 -> 140427268549888
	140427268549888 [label=AccumulateGrad]
	140427268549312 -> 140427605726352
	140427556690176 [label="decoder.resblockup_3.block.0.3.weight
 (128)" fillcolor=lightblue]
	140427556690176 -> 140427268549312
	140427268549312 [label=AccumulateGrad]
	140427268549264 -> 140427605726352
	140427556690256 [label="decoder.resblockup_3.block.0.3.bias
 (128)" fillcolor=lightblue]
	140427556690256 -> 140427268549264
	140427268549264 [label=AccumulateGrad]
	140427605725536 -> 140427605720464
	140427556690576 [label="decoder.resblockup_3.block.0.5.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	140427556690576 -> 140427605725536
	140427605725536 [label=AccumulateGrad]
	140427605725344 -> 140427605720464
	140427556690656 [label="decoder.resblockup_3.block.0.5.bias
 (128)" fillcolor=lightblue]
	140427556690656 -> 140427605725344
	140427605725344 [label=AccumulateGrad]
	140427605720896 -> 140427605720752
	140427605720896 [label=ConvolutionBackward0]
	140427605725968 -> 140427605720896
	140427605725968 [label=ReluBackward0]
	140427268550464 -> 140427605725968
	140427268550464 [label=NativeBatchNormBackward0]
	140427268550560 -> 140427268550464
	140427268550560 [label=ConvolutionBackward0]
	140427268608160 -> 140427268550560
	140427268608160 [label=ReluBackward0]
	140427268608352 -> 140427268608160
	140427268608352 [label=NativeBatchNormBackward0]
	140427605720800 -> 140427268608352
	140427268608448 -> 140427268608352
	140427556690736 [label="decoder.resblockup_3.block.1.0.weight
 (128)" fillcolor=lightblue]
	140427556690736 -> 140427268608448
	140427268608448 [label=AccumulateGrad]
	140427268608400 -> 140427268608352
	140427556690816 [label="decoder.resblockup_3.block.1.0.bias
 (128)" fillcolor=lightblue]
	140427556690816 -> 140427268608400
	140427268608400 [label=AccumulateGrad]
	140427268608112 -> 140427268550560
	140427556691136 [label="decoder.resblockup_3.block.1.2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	140427556691136 -> 140427268608112
	140427268608112 [label=AccumulateGrad]
	140427268608064 -> 140427268550560
	140427556691216 [label="decoder.resblockup_3.block.1.2.bias
 (128)" fillcolor=lightblue]
	140427556691216 -> 140427268608064
	140427268608064 [label=AccumulateGrad]
	140427268550512 -> 140427268550464
	140427556691296 [label="decoder.resblockup_3.block.1.3.weight
 (128)" fillcolor=lightblue]
	140427556691296 -> 140427268550512
	140427268550512 [label=AccumulateGrad]
	140427268550272 -> 140427268550464
	140427556691376 [label="decoder.resblockup_3.block.1.3.bias
 (128)" fillcolor=lightblue]
	140427556691376 -> 140427268550272
	140427268550272 [label=AccumulateGrad]
	140427605725776 -> 140427605720896
	140427556691696 [label="decoder.resblockup_3.block.1.5.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	140427556691696 -> 140427605725776
	140427605725776 [label=AccumulateGrad]
	140427268549696 -> 140427605720896
	140427556691776 [label="decoder.resblockup_3.block.1.5.bias
 (128)" fillcolor=lightblue]
	140427556691776 -> 140427268549696
	140427268549696 [label=AccumulateGrad]
	140427605720944 -> 140427605720752
	140427605720944 [label=ConvolutionBackward0]
	140427268550608 -> 140427605720944
	140427268550608 [label=ReluBackward0]
	140427268608496 -> 140427268550608
	140427268608496 [label=NativeBatchNormBackward0]
	140427268608592 -> 140427268608496
	140427268608592 [label=ConvolutionBackward0]
	140427268608784 -> 140427268608592
	140427268608784 [label=ReluBackward0]
	140427268608976 -> 140427268608784
	140427268608976 [label=NativeBatchNormBackward0]
	140427605720800 -> 140427268608976
	140427268609072 -> 140427268608976
	140427556691856 [label="decoder.resblockup_3.block.2.0.weight
 (128)" fillcolor=lightblue]
	140427556691856 -> 140427268609072
	140427268609072 [label=AccumulateGrad]
	140427268609024 -> 140427268608976
	140427556790336 [label="decoder.resblockup_3.block.2.0.bias
 (128)" fillcolor=lightblue]
	140427556790336 -> 140427268609024
	140427268609024 [label=AccumulateGrad]
	140427268608736 -> 140427268608592
	140427556790656 [label="decoder.resblockup_3.block.2.2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	140427556790656 -> 140427268608736
	140427268608736 [label=AccumulateGrad]
	140427268608688 -> 140427268608592
	140427556790736 [label="decoder.resblockup_3.block.2.2.bias
 (128)" fillcolor=lightblue]
	140427556790736 -> 140427268608688
	140427268608688 [label=AccumulateGrad]
	140427268608544 -> 140427268608496
	140427556790816 [label="decoder.resblockup_3.block.2.3.weight
 (128)" fillcolor=lightblue]
	140427556790816 -> 140427268608544
	140427268608544 [label=AccumulateGrad]
	140427268608304 -> 140427268608496
	140427556790896 [label="decoder.resblockup_3.block.2.3.bias
 (128)" fillcolor=lightblue]
	140427556790896 -> 140427268608304
	140427268608304 [label=AccumulateGrad]
	140427268550224 -> 140427605720944
	140427556791216 [label="decoder.resblockup_3.block.2.5.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	140427556791216 -> 140427268550224
	140427268550224 [label=AccumulateGrad]
	140427268550176 -> 140427605720944
	140427556791296 [label="decoder.resblockup_3.block.2.5.bias
 (128)" fillcolor=lightblue]
	140427556791296 -> 140427268550176
	140427268550176 [label=AccumulateGrad]
	140427605720368 -> 140427605720224
	140427605720176 -> 140427605720032
	140427599854224 [label="decoder.combine_4.conv2DN.0.weight
 (64, 192, 1, 1)" fillcolor=lightblue]
	140427599854224 -> 140427605720176
	140427605720176 [label=AccumulateGrad]
	140427605720128 -> 140427605720032
	140427599854304 [label="decoder.combine_4.conv2DN.0.bias
 (64)" fillcolor=lightblue]
	140427599854304 -> 140427605720128
	140427605720128 [label=AccumulateGrad]
	140427605719984 -> 140427605719744
	140427599854384 [label="decoder.combine_4.conv2DN.1.weight
 (64)" fillcolor=lightblue]
	140427599854384 -> 140427605719984
	140427605719984 [label=AccumulateGrad]
	140427605719936 -> 140427605719744
	140427599854464 [label="decoder.combine_4.conv2DN.1.bias
 (64)" fillcolor=lightblue]
	140427599854464 -> 140427605719936
	140427605719936 [label=AccumulateGrad]
	140427605719696 -> 140427605719648
	140427605719696 [label=ConvolutionBackward0]
	140427605720320 -> 140427605719696
	140427605720320 [label=ReluBackward0]
	140427605720992 -> 140427605720320
	140427605720992 [label=NativeBatchNormBackward0]
	140427605720608 -> 140427605720992
	140427605720608 [label=ConvolutionBackward0]
	140427268608880 -> 140427605720608
	140427268608880 [label=ReluBackward0]
	140427268609264 -> 140427268608880
	140427268609264 [label=NativeBatchNormBackward0]
	140427605719744 -> 140427268609264
	140427268609360 -> 140427268609264
	140427556791376 [label="decoder.resblockup_4.block.0.0.weight
 (64)" fillcolor=lightblue]
	140427556791376 -> 140427268609360
	140427268609360 [label=AccumulateGrad]
	140427268609312 -> 140427268609264
	140427556791456 [label="decoder.resblockup_4.block.0.0.bias
 (64)" fillcolor=lightblue]
	140427556791456 -> 140427268609312
	140427268609312 [label=AccumulateGrad]
	140427268608928 -> 140427605720608
	140427556791856 [label="decoder.resblockup_4.block.0.2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140427556791856 -> 140427268608928
	140427268608928 [label=AccumulateGrad]
	140427268608832 -> 140427605720608
	140427556791936 [label="decoder.resblockup_4.block.0.2.bias
 (64)" fillcolor=lightblue]
	140427556791936 -> 140427268608832
	140427268608832 [label=AccumulateGrad]
	140427268608256 -> 140427605720992
	140427556792016 [label="decoder.resblockup_4.block.0.3.weight
 (64)" fillcolor=lightblue]
	140427556792016 -> 140427268608256
	140427268608256 [label=AccumulateGrad]
	140427268608208 -> 140427605720992
	140427556792096 [label="decoder.resblockup_4.block.0.3.bias
 (64)" fillcolor=lightblue]
	140427556792096 -> 140427268608208
	140427268608208 [label=AccumulateGrad]
	140427605720272 -> 140427605719696
	140427556792416 [label="decoder.resblockup_4.block.0.5.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140427556792416 -> 140427605720272
	140427605720272 [label=AccumulateGrad]
	140427605720080 -> 140427605719696
	140427556792496 [label="decoder.resblockup_4.block.0.5.bias
 (64)" fillcolor=lightblue]
	140427556792496 -> 140427605720080
	140427605720080 [label=AccumulateGrad]
	140427605719360 -> 140427605719648
	140427605719360 [label=ConvolutionBackward0]
	140427605720704 -> 140427605719360
	140427605720704 [label=ReluBackward0]
	140427268609408 -> 140427605720704
	140427268609408 [label=NativeBatchNormBackward0]
	140427268609504 -> 140427268609408
	140427268609504 [label=ConvolutionBackward0]
	140427268609696 -> 140427268609504
	140427268609696 [label=ReluBackward0]
	140427268609888 -> 140427268609696
	140427268609888 [label=NativeBatchNormBackward0]
	140427605719744 -> 140427268609888
	140427268609984 -> 140427268609888
	140427556792576 [label="decoder.resblockup_4.block.1.0.weight
 (64)" fillcolor=lightblue]
	140427556792576 -> 140427268609984
	140427268609984 [label=AccumulateGrad]
	140427268609936 -> 140427268609888
	140427556792656 [label="decoder.resblockup_4.block.1.0.bias
 (64)" fillcolor=lightblue]
	140427556792656 -> 140427268609936
	140427268609936 [label=AccumulateGrad]
	140427268609648 -> 140427268609504
	140427556792976 [label="decoder.resblockup_4.block.1.2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140427556792976 -> 140427268609648
	140427268609648 [label=AccumulateGrad]
	140427268609600 -> 140427268609504
	140427556793056 [label="decoder.resblockup_4.block.1.2.bias
 (64)" fillcolor=lightblue]
	140427556793056 -> 140427268609600
	140427268609600 [label=AccumulateGrad]
	140427268609456 -> 140427268609408
	140427556793136 [label="decoder.resblockup_4.block.1.3.weight
 (64)" fillcolor=lightblue]
	140427556793136 -> 140427268609456
	140427268609456 [label=AccumulateGrad]
	140427268609216 -> 140427268609408
	140427556793216 [label="decoder.resblockup_4.block.1.3.bias
 (64)" fillcolor=lightblue]
	140427556793216 -> 140427268609216
	140427268609216 [label=AccumulateGrad]
	140427605720512 -> 140427605719360
	140427556793536 [label="decoder.resblockup_4.block.1.5.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140427556793536 -> 140427605720512
	140427605720512 [label=AccumulateGrad]
	140427268608640 -> 140427605719360
	140427556793616 [label="decoder.resblockup_4.block.1.5.bias
 (64)" fillcolor=lightblue]
	140427556793616 -> 140427268608640
	140427268608640 [label=AccumulateGrad]
	140427605719792 -> 140427605719648
	140427605719792 [label=ConvolutionBackward0]
	140427268609552 -> 140427605719792
	140427268609552 [label=ReluBackward0]
	140427268610032 -> 140427268609552
	140427268610032 [label=NativeBatchNormBackward0]
	140427268610128 -> 140427268610032
	140427268610128 [label=ConvolutionBackward0]
	140427268610320 -> 140427268610128
	140427268610320 [label=ReluBackward0]
	140427268610512 -> 140427268610320
	140427268610512 [label=NativeBatchNormBackward0]
	140427605719744 -> 140427268610512
	140427268610608 -> 140427268610512
	140427556793696 [label="decoder.resblockup_4.block.2.0.weight
 (64)" fillcolor=lightblue]
	140427556793696 -> 140427268610608
	140427268610608 [label=AccumulateGrad]
	140427268610560 -> 140427268610512
	140427556793776 [label="decoder.resblockup_4.block.2.0.bias
 (64)" fillcolor=lightblue]
	140427556793776 -> 140427268610560
	140427268610560 [label=AccumulateGrad]
	140427268610272 -> 140427268610128
	140427556794096 [label="decoder.resblockup_4.block.2.2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140427556794096 -> 140427268610272
	140427268610272 [label=AccumulateGrad]
	140427268610224 -> 140427268610128
	140427556794176 [label="decoder.resblockup_4.block.2.2.bias
 (64)" fillcolor=lightblue]
	140427556794176 -> 140427268610224
	140427268610224 [label=AccumulateGrad]
	140427268610080 -> 140427268610032
	140427556794256 [label="decoder.resblockup_4.block.2.3.weight
 (64)" fillcolor=lightblue]
	140427556794256 -> 140427268610080
	140427268610080 [label=AccumulateGrad]
	140427268609840 -> 140427268610032
	140427599749184 [label="decoder.resblockup_4.block.2.3.bias
 (64)" fillcolor=lightblue]
	140427599749184 -> 140427268609840
	140427268609840 [label=AccumulateGrad]
	140427268609168 -> 140427605719792
	140427599749504 [label="decoder.resblockup_4.block.2.5.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140427599749504 -> 140427268609168
	140427268609168 [label=AccumulateGrad]
	140427268609120 -> 140427605719792
	140427599749584 [label="decoder.resblockup_4.block.2.5.bias
 (64)" fillcolor=lightblue]
	140427599749584 -> 140427268609120
	140427268609120 [label=AccumulateGrad]
	140427605719840 -> 140427605719648
	140427605719840 [label=ConvolutionBackward0]
	140427268610176 -> 140427605719840
	140427268610176 [label=ReluBackward0]
	140427268610656 -> 140427268610176
	140427268610656 [label=NativeBatchNormBackward0]
	140427268610752 -> 140427268610656
	140427268610752 [label=ConvolutionBackward0]
	140427268610944 -> 140427268610752
	140427268610944 [label=ReluBackward0]
	140427268611136 -> 140427268610944
	140427268611136 [label=NativeBatchNormBackward0]
	140427605719744 -> 140427268611136
	140427268611232 -> 140427268611136
	140427599749664 [label="decoder.resblockup_4.block.3.0.weight
 (64)" fillcolor=lightblue]
	140427599749664 -> 140427268611232
	140427268611232 [label=AccumulateGrad]
	140427268611184 -> 140427268611136
	140427599749744 [label="decoder.resblockup_4.block.3.0.bias
 (64)" fillcolor=lightblue]
	140427599749744 -> 140427268611184
	140427268611184 [label=AccumulateGrad]
	140427268610896 -> 140427268610752
	140427599750064 [label="decoder.resblockup_4.block.3.2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140427599750064 -> 140427268610896
	140427268610896 [label=AccumulateGrad]
	140427268610848 -> 140427268610752
	140427599750144 [label="decoder.resblockup_4.block.3.2.bias
 (64)" fillcolor=lightblue]
	140427599750144 -> 140427268610848
	140427268610848 [label=AccumulateGrad]
	140427268610704 -> 140427268610656
	140427599750224 [label="decoder.resblockup_4.block.3.3.weight
 (64)" fillcolor=lightblue]
	140427599750224 -> 140427268610704
	140427268610704 [label=AccumulateGrad]
	140427268610464 -> 140427268610656
	140427599750304 [label="decoder.resblockup_4.block.3.3.bias
 (64)" fillcolor=lightblue]
	140427599750304 -> 140427268610464
	140427268610464 [label=AccumulateGrad]
	140427268609792 -> 140427605719840
	140427599750624 [label="decoder.resblockup_4.block.3.5.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140427599750624 -> 140427268609792
	140427268609792 [label=AccumulateGrad]
	140427268609744 -> 140427605719840
	140427599750704 [label="decoder.resblockup_4.block.3.5.bias
 (64)" fillcolor=lightblue]
	140427599750704 -> 140427268609744
	140427268609744 [label=AccumulateGrad]
	140427605719264 -> 140427605719120
	140427605719072 -> 140427605718928
	140427599854784 [label="decoder.combine_5.conv2DN.0.weight
 (32, 96, 1, 1)" fillcolor=lightblue]
	140427599854784 -> 140427605719072
	140427605719072 [label=AccumulateGrad]
	140427605719024 -> 140427605718928
	140427599854864 [label="decoder.combine_5.conv2DN.0.bias
 (32)" fillcolor=lightblue]
	140427599854864 -> 140427605719024
	140427605719024 [label=AccumulateGrad]
	140427605718880 -> 140427605718688
	140427599854944 [label="decoder.combine_5.conv2DN.1.weight
 (32)" fillcolor=lightblue]
	140427599854944 -> 140427605718880
	140427605718880 [label=AccumulateGrad]
	140427605718832 -> 140427605718688
	140427599855024 [label="decoder.combine_5.conv2DN.1.bias
 (32)" fillcolor=lightblue]
	140427599855024 -> 140427605718832
	140427605718832 [label=AccumulateGrad]
	140427605718640 -> 140427605718592
	140427605718640 [label=ConvolutionBackward0]
	140427605719216 -> 140427605718640
	140427605719216 [label=ReluBackward0]
	140427605719888 -> 140427605719216
	140427605719888 [label=NativeBatchNormBackward0]
	140427605719504 -> 140427605719888
	140427605719504 [label=ConvolutionBackward0]
	140427268611040 -> 140427605719504
	140427268611040 [label=ReluBackward0]
	140427268611424 -> 140427268611040
	140427268611424 [label=NativeBatchNormBackward0]
	140427605718688 -> 140427268611424
	140427268611520 -> 140427268611424
	140427599750544 [label="decoder.resblockup_5.block.0.0.weight
 (32)" fillcolor=lightblue]
	140427599750544 -> 140427268611520
	140427268611520 [label=AccumulateGrad]
	140427268611472 -> 140427268611424
	140427599750784 [label="decoder.resblockup_5.block.0.0.bias
 (32)" fillcolor=lightblue]
	140427599750784 -> 140427268611472
	140427268611472 [label=AccumulateGrad]
	140427268611088 -> 140427605719504
	140427599751184 [label="decoder.resblockup_5.block.0.2.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140427599751184 -> 140427268611088
	140427268611088 [label=AccumulateGrad]
	140427268610992 -> 140427605719504
	140427599751264 [label="decoder.resblockup_5.block.0.2.bias
 (32)" fillcolor=lightblue]
	140427599751264 -> 140427268610992
	140427268610992 [label=AccumulateGrad]
	140427268610416 -> 140427605719888
	140427599751344 [label="decoder.resblockup_5.block.0.3.weight
 (32)" fillcolor=lightblue]
	140427599751344 -> 140427268610416
	140427268610416 [label=AccumulateGrad]
	140427268610368 -> 140427605719888
	140427599751424 [label="decoder.resblockup_5.block.0.3.bias
 (32)" fillcolor=lightblue]
	140427599751424 -> 140427268610368
	140427268610368 [label=AccumulateGrad]
	140427605719168 -> 140427605718640
	140427599751744 [label="decoder.resblockup_5.block.0.5.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140427599751744 -> 140427605719168
	140427605719168 [label=AccumulateGrad]
	140427605718976 -> 140427605718640
	140427599751824 [label="decoder.resblockup_5.block.0.5.bias
 (32)" fillcolor=lightblue]
	140427599751824 -> 140427605718976
	140427605718976 [label=AccumulateGrad]
	140427605718400 -> 140427605718592
	140427605718400 [label=ConvolutionBackward0]
	140427605719600 -> 140427605718400
	140427605719600 [label=ReluBackward0]
	140427268611568 -> 140427605719600
	140427268611568 [label=NativeBatchNormBackward0]
	140427268611664 -> 140427268611568
	140427268611664 [label=ConvolutionBackward0]
	140427268611856 -> 140427268611664
	140427268611856 [label=ReluBackward0]
	140427268612048 -> 140427268611856
	140427268612048 [label=NativeBatchNormBackward0]
	140427605718688 -> 140427268612048
	140427268611952 -> 140427268612048
	140427599751904 [label="decoder.resblockup_5.block.1.0.weight
 (32)" fillcolor=lightblue]
	140427599751904 -> 140427268611952
	140427268611952 [label=AccumulateGrad]
	140427268653168 -> 140427268612048
	140427599751984 [label="decoder.resblockup_5.block.1.0.bias
 (32)" fillcolor=lightblue]
	140427599751984 -> 140427268653168
	140427268653168 [label=AccumulateGrad]
	140427268611808 -> 140427268611664
	140427599752304 [label="decoder.resblockup_5.block.1.2.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140427599752304 -> 140427268611808
	140427268611808 [label=AccumulateGrad]
	140427268611760 -> 140427268611664
	140427599752384 [label="decoder.resblockup_5.block.1.2.bias
 (32)" fillcolor=lightblue]
	140427599752384 -> 140427268611760
	140427268611760 [label=AccumulateGrad]
	140427268611616 -> 140427268611568
	140427599752464 [label="decoder.resblockup_5.block.1.3.weight
 (32)" fillcolor=lightblue]
	140427599752464 -> 140427268611616
	140427268611616 [label=AccumulateGrad]
	140427268611376 -> 140427268611568
	140427599752544 [label="decoder.resblockup_5.block.1.3.bias
 (32)" fillcolor=lightblue]
	140427599752544 -> 140427268611376
	140427268611376 [label=AccumulateGrad]
	140427605719408 -> 140427605718400
	140427599752864 [label="decoder.resblockup_5.block.1.5.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140427599752864 -> 140427605719408
	140427605719408 [label=AccumulateGrad]
	140427268610800 -> 140427605718400
	140427599752944 [label="decoder.resblockup_5.block.1.5.bias
 (32)" fillcolor=lightblue]
	140427599752944 -> 140427268610800
	140427268610800 [label=AccumulateGrad]
	140427605718736 -> 140427605718592
	140427605718736 [label=ConvolutionBackward0]
	140427268611712 -> 140427605718736
	140427268611712 [label=ReluBackward0]
	140427268612000 -> 140427268611712
	140427268612000 [label=NativeBatchNormBackward0]
	140427268653312 -> 140427268612000
	140427268653312 [label=ConvolutionBackward0]
	140427268653504 -> 140427268653312
	140427268653504 [label=ReluBackward0]
	140427268653696 -> 140427268653504
	140427268653696 [label=NativeBatchNormBackward0]
	140427605718688 -> 140427268653696
	140427268653792 -> 140427268653696
	140427599753024 [label="decoder.resblockup_5.block.2.0.weight
 (32)" fillcolor=lightblue]
	140427599753024 -> 140427268653792
	140427268653792 [label=AccumulateGrad]
	140427268653744 -> 140427268653696
	140427599753104 [label="decoder.resblockup_5.block.2.0.bias
 (32)" fillcolor=lightblue]
	140427599753104 -> 140427268653744
	140427268653744 [label=AccumulateGrad]
	140427268653456 -> 140427268653312
	140427599851824 [label="decoder.resblockup_5.block.2.2.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140427599851824 -> 140427268653456
	140427268653456 [label=AccumulateGrad]
	140427268653408 -> 140427268653312
	140427599851904 [label="decoder.resblockup_5.block.2.2.bias
 (32)" fillcolor=lightblue]
	140427599851904 -> 140427268653408
	140427268653408 [label=AccumulateGrad]
	140427268653264 -> 140427268612000
	140427599851984 [label="decoder.resblockup_5.block.2.3.weight
 (32)" fillcolor=lightblue]
	140427599851984 -> 140427268653264
	140427268653264 [label=AccumulateGrad]
	140427268653120 -> 140427268612000
	140427599852064 [label="decoder.resblockup_5.block.2.3.bias
 (32)" fillcolor=lightblue]
	140427599852064 -> 140427268653120
	140427268653120 [label=AccumulateGrad]
	140427268611328 -> 140427605718736
	140427599852384 [label="decoder.resblockup_5.block.2.5.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140427599852384 -> 140427268611328
	140427268611328 [label=AccumulateGrad]
	140427268611280 -> 140427605718736
	140427599852464 [label="decoder.resblockup_5.block.2.5.bias
 (32)" fillcolor=lightblue]
	140427599852464 -> 140427268611280
	140427268611280 [label=AccumulateGrad]
	140427605718304 -> 140427605718160
	140427605718112 -> 140427605717968
	140427599855344 [label="decoder.combine_6.conv2DN.0.weight
 (32, 64, 1, 1)" fillcolor=lightblue]
	140427599855344 -> 140427605718112
	140427605718112 [label=AccumulateGrad]
	140427605718064 -> 140427605717968
	140427599855424 [label="decoder.combine_6.conv2DN.0.bias
 (32)" fillcolor=lightblue]
	140427599855424 -> 140427605718064
	140427605718064 [label=AccumulateGrad]
	140427605717920 -> 140427605717872
	140427599855504 [label="decoder.combine_6.conv2DN.1.weight
 (32)" fillcolor=lightblue]
	140427599855504 -> 140427605717920
	140427605717920 [label=AccumulateGrad]
	140427605717680 -> 140427605717872
	140427605520448 [label="decoder.combine_6.conv2DN.1.bias
 (32)" fillcolor=lightblue]
	140427605520448 -> 140427605717680
	140427605717680 [label=AccumulateGrad]
	140427605717536 -> 140427605717392
	140427605520768 [label="decoder.psp.parrallel_list.0.2.weight
 (8, 32, 1, 1)" fillcolor=lightblue]
	140427605520768 -> 140427605717536
	140427605717536 [label=AccumulateGrad]
	140427605717488 -> 140427605717392
	140427605520848 [label="decoder.psp.parrallel_list.0.2.bias
 (8)" fillcolor=lightblue]
	140427605520848 -> 140427605717488
	140427605717488 [label=AccumulateGrad]
	140427605717344 -> 140427605717152
	140427605520928 [label="decoder.psp.parrallel_list.0.3.weight
 (8)" fillcolor=lightblue]
	140427605520928 -> 140427605717344
	140427605717344 [label=AccumulateGrad]
	140427605717296 -> 140427605717152
	140427605521008 [label="decoder.psp.parrallel_list.0.3.bias
 (8)" fillcolor=lightblue]
	140427605521008 -> 140427605717296
	140427605717296 [label=AccumulateGrad]
	140427605717104 -> 140427599847328
	140427605717104 [label=NativeBatchNormBackward0]
	140427605717728 -> 140427605717104
	140427605717728 [label=ConvolutionBackward0]
	140427605718256 -> 140427605717728
	140427605718256 [label=UpsampleNearest2DBackward1]
	140427268611904 -> 140427605718256
	140427268611904 [label=MaxPool2DWithIndicesBackward0]
	140427605717872 -> 140427268611904
	140427605718208 -> 140427605717728
	140427605521328 [label="decoder.psp.parrallel_list.1.2.weight
 (8, 32, 1, 1)" fillcolor=lightblue]
	140427605521328 -> 140427605718208
	140427605718208 [label=AccumulateGrad]
	140427605718016 -> 140427605717728
	140427605521408 [label="decoder.psp.parrallel_list.1.2.bias
 (8)" fillcolor=lightblue]
	140427605521408 -> 140427605718016
	140427605718016 [label=AccumulateGrad]
	140427605717632 -> 140427605717104
	140427605521488 [label="decoder.psp.parrallel_list.1.3.weight
 (8)" fillcolor=lightblue]
	140427605521488 -> 140427605717632
	140427605717632 [label=AccumulateGrad]
	140427605717440 -> 140427605717104
	140427605521568 [label="decoder.psp.parrallel_list.1.3.bias
 (8)" fillcolor=lightblue]
	140427605521568 -> 140427605717440
	140427605717440 [label=AccumulateGrad]
	140427605717056 -> 140427599847328
	140427605717056 [label=NativeBatchNormBackward0]
	140427605718784 -> 140427605717056
	140427605718784 [label=ConvolutionBackward0]
	140427268653552 -> 140427605718784
	140427268653552 [label=UpsampleNearest2DBackward1]
	140427268653888 -> 140427268653552
	140427268653888 [label=MaxPool2DWithIndicesBackward0]
	140427605717872 -> 140427268653888
	140427268653216 -> 140427605718784
	140427605521888 [label="decoder.psp.parrallel_list.2.2.weight
 (8, 32, 1, 1)" fillcolor=lightblue]
	140427605521888 -> 140427268653216
	140427268653216 [label=AccumulateGrad]
	140427268653360 -> 140427605718784
	140427605521968 [label="decoder.psp.parrallel_list.2.2.bias
 (8)" fillcolor=lightblue]
	140427605521968 -> 140427268653360
	140427268653360 [label=AccumulateGrad]
	140427605718448 -> 140427605717056
	140427605522048 [label="decoder.psp.parrallel_list.2.3.weight
 (8)" fillcolor=lightblue]
	140427605522048 -> 140427605718448
	140427605718448 [label=AccumulateGrad]
	140427605717824 -> 140427605717056
	140427605522128 [label="decoder.psp.parrallel_list.2.3.bias
 (8)" fillcolor=lightblue]
	140427605522128 -> 140427605717824
	140427605717824 [label=AccumulateGrad]
	140427605717200 -> 140427599847328
	140427605717200 [label=NativeBatchNormBackward0]
	140427605718544 -> 140427605717200
	140427605718544 [label=ConvolutionBackward0]
	140427268654032 -> 140427605718544
	140427268654032 [label=UpsampleNearest2DBackward1]
	140427268654224 -> 140427268654032
	140427268654224 [label=MaxPool2DWithIndicesBackward0]
	140427605717872 -> 140427268654224
	140427268653600 -> 140427605718544
	140427605522448 [label="decoder.psp.parrallel_list.3.2.weight
 (8, 32, 1, 1)" fillcolor=lightblue]
	140427605522448 -> 140427268653600
	140427268653600 [label=AccumulateGrad]
	140427268653936 -> 140427605718544
	140427605522528 [label="decoder.psp.parrallel_list.3.2.bias
 (8)" fillcolor=lightblue]
	140427605522528 -> 140427268653936
	140427268653936 [label=AccumulateGrad]
	140427268653840 -> 140427605717200
	140427605522608 [label="decoder.psp.parrallel_list.3.3.weight
 (8)" fillcolor=lightblue]
	140427605522608 -> 140427268653840
	140427268653840 [label=AccumulateGrad]
	140427268653648 -> 140427605717200
	140427605522688 [label="decoder.psp.parrallel_list.3.3.bias
 (8)" fillcolor=lightblue]
	140427605522688 -> 140427268653648
	140427268653648 [label=AccumulateGrad]
	140427599847280 -> 140427599847136
	140427605522928 [label="decoder.psp.conv.0.weight
 (32, 32, 1, 1)" fillcolor=lightblue]
	140427605522928 -> 140427599847280
	140427599847280 [label=AccumulateGrad]
	140427599847232 -> 140427599847136
	140427605523008 [label="decoder.psp.conv.0.bias
 (32)" fillcolor=lightblue]
	140427605523008 -> 140427599847232
	140427599847232 [label=AccumulateGrad]
	140427599847088 -> 140427599846848
	140427605523088 [label="decoder.psp.conv.1.weight
 (32)" fillcolor=lightblue]
	140427605523088 -> 140427599847088
	140427599847088 [label=AccumulateGrad]
	140427599846800 -> 140427599846848
	140427605523168 [label="decoder.psp.conv.1.bias
 (32)" fillcolor=lightblue]
	140427605523168 -> 140427599846800
	140427599846800 [label=AccumulateGrad]
	140427599847040 -> 140427599846992
	140427605523568 [label="decoder.last_conv.weight
 (13, 32, 1, 1)" fillcolor=lightblue]
	140427605523568 -> 140427599847040
	140427599847040 [label=AccumulateGrad]
	140427599846944 -> 140427599846992
	140427605523648 [label="decoder.last_conv.bias
 (13)" fillcolor=lightblue]
	140427605523648 -> 140427599846944
	140427599846944 [label=AccumulateGrad]
	140427599846704 -> 140427605628064
}
